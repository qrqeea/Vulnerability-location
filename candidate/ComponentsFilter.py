import os
import tqdm
import difflib
from util.io_util import load_pickle, save_text, save_json, save_pickle, load_json
from util.general_util import rule_based_filtering
from .FileSelection import FileSelection
from .FunctionSelection import FunctionSelection
from .ModuleSelection import ModuleSelection


class ComponentsFilter:

    def __init__(self, module_root_path: str, cve_data_all: dict, repo_file_list: dict):
        self.module_root_path = module_root_path
        self.cve_data_all = cve_data_all
        self.repo_file_list = repo_file_list

        os.makedirs(self.module_root_path, exist_ok = True)

        self.file_component_dir = f'{self.module_root_path}/file'
        self.function_component_dir = f'{self.module_root_path}/function'
        self.module_component_dir = f'{self.module_root_path}/module'

    def start(self):
        fileSelection = FileSelection(
            module_root_path = self.file_component_dir,
            cve_data_all = self.cve_data_all,
            repo_file_list = self.repo_file_list,
            threshold = 0.8
        )
        file_res = fileSelection.filter_files()
        print(f'cve_list_done: {len(file_res)}')
        # self.check_recall(file_res)
        # print(233, len(cve_list_done))
        
        # functionSelection = FunctionSelection(
        #     module_root_path = self.function_component_dir,
        #     repo_path = self.repo_path,
        #     cve_data_all = self.cve_data_all,
        #     cve_list_done = cve_list_done
        # )
        # function_res = functionSelection.retrieve()
        # # self.check_recall(function_res)

        # # self.check_recall(self.union_result([file_res, function_res]))
        
        # # save_pickle(f'{self.module_component_dir}/cve_list_5924.pkl', cve_list_done)
        # # cve_list_done = load_pickle(f'{self.module_component_dir}/cve_list_5924.pkl')

        # cve_list_done = list(set(file_res.keys() | set(function_res.keys())))
        # # print(233, len(cve_list_done))
        # moduleSelection = ModuleSelection(
        #     module_root_path = self.module_component_dir,
        #     repo_path = self.repo_path,
        #     cve_data_all = self.cve_data_all,
        #     cve_list_done = cve_list_done,
        #     repo_file_list = self.repo_file_list
        # )
        # module_res = moduleSelection.retrieve()
        # # self.check_recall(module_res)

        # union_res = self.union_result([file_res, function_res, module_res])
        # self.check_recall(union_res)


    def retrieve(self, k: int, similarity_threshold: float, similarity_algorithm = difflib.SequenceMatcher):
        
        os.makedirs(f'{self.module_root_path}/candidate_list', exist_ok = True)
        res_path = f'{self.module_root_path}/candidate_list/candidates_{k}_{similarity_threshold}_{similarity_algorithm.__name__}.json'
        # if os.path.exists(res_path) and os.path.exists(f'{self.module_root_path}/cve_list_done.pkl'):
        #     return load_json(res_path), load_pickle(f'{self.module_root_path}/cve_list_done.pkl')
        
        candidates_100_path = f'{self.module_root_path}/candidate_list/candidates_100_{similarity_algorithm.__name__}.json'
        
        candidates_100 = load_json(candidates_100_path) if os.path.exists(candidates_100_path) else {}
        updated = False
        for cve in tqdm.tqdm(self.cve_list):
            if cve in candidates_100:
                continue
            candidates_100[cve] = {}
            file_components = self.cve_data_all[cve].get('components').get('File')
            for repo, sha in self.cve_data_all[cve]['collected_commit']:
                repo_file_list = self.repo_file_list[repo][sha]
                related_files = self.find_related_files(file_components, repo_file_list, 100, similarity_algorithm)
                candidates_100[cve][repo] = related_files
                updated = True
        if updated:
            save_json(candidates_100_path, candidates_100)
        
        print('start reduce data')
        cve_list_done = []
        reduced_data = {}
        for cve, v in candidates_100.items():
            reduced_data[cve] = {}
            flag = False
            for repo, triple_list in v.items():
                tp = []
                for index, triple in enumerate(triple_list):
                    if index >= k and triple[2] != triple_list[index - 1][2]:
                        break
                    if triple[2] >= similarity_threshold:
                        flag = True
                    tp.append(triple[1])
                if tp:
                    reduced_data[cve][repo] = tp
            if flag:
                cve_list_done.append(cve)
            if not reduced_data[cve]:
                del reduced_data[cve]
        
        save_json(res_path, reduced_data)
        save_text(f'{self.module_root_path}/cve_list_done', cve_list_done)
        save_pickle(f'{self.module_root_path}/cve_list_done.pkl', cve_list_done)
        
        print('end reduce data')
        return reduced_data, cve_list_done


    def find_related_files(self, keywords: list, files: list, k: int, similarity_algorithm):
        # components中包含'/'则匹配完整路径，否则只匹配文件名
        res = []
        for keyword in keywords:
            for full_path, isdir in files:
                if isdir: continue
                file_lower = full_path.lower()
                file_name = file_lower.split('/')[-1]
                file_path = '/'.join(file_lower.split('/')[:-1])
                if not rule_based_filtering(file_name, file_path):
                    continue

                keyword_lower = keyword.lower()
                if '/' not in keyword:
                    keyword_lower = keyword_lower.split('/')[-1]
                    file_lower = file_name
                
                if similarity_algorithm.__name__ == 'SequenceMatcher':
                    similarity = difflib.SequenceMatcher(None, keyword_lower, file_lower).ratio()
                elif similarity_algorithm.__name__ == 'ngram_similarity':
                    similarity = ngram_similarity(keyword_lower, file_lower, 2)
                else:
                    similarity = similarity_algorithm(keyword_lower, file_lower)
                res.append((keyword, full_path, similarity))
        sorted_res = sorted(res, key = lambda x: x[2], reverse = (similarity_algorithm.__name__ != 'levenshtein_distance'))
        # sorted_res = sorted(res, key = lambda x: x[2])
        return sorted_res[:k]