# def codebert(self, cve_list_done: set):
    #     cve_list_path = f'{self.codebert_dir}/cve_list'
    #     if not os.path.exists(f'{cve_list_path}.pkl'):
    #         cve_list = {cve for cve, v in self.cve_data_all.items() if 'collected_commit' in v} - cve_list_done
    #         cve_list = list(cve_list)
    #         save_text(cve_list_path, cve_list)
    #         save_pickle(f'{cve_list_path}.pkl', cve_list)
    #     else:
    #         cve_list = load_pickle(f'{cve_list_path}.pkl')
    #     print(f'{len(cve_list)}')   # 4176

    #     print('start check if vulnerability file in collected commit')
    #     incorrect_cve_list = []
    #     positive_label_list = []
    #     for cve in tqdm.tqdm(cve_list):
    #         flag = False
    #         for repo, sha in self.cve_data_all[cve]['collected_commit']:
    #             if flag: break
    #             if repo in self.cve_data_all[cve]['vulnerability_files']:   # repo相同，file相同
    #                 file_ans_list = self.cve_data_all[cve]['vulnerability_files'][repo]
    #             else:
    #                 file_ans_list = self.cve_data_all[cve]['file_list']     # repo不同，file相同
    #             for file_ans in file_ans_list:
    #                 file_ans = file_ans.lower()
    #                 for file_candidate, _ in self.repo_file_list[repo][sha]:
    #                     if file_ans.lower() == file_candidate.lower():
    #                         flag = True
    #                         positive_label_list.append((cve, repo, file_candidate))
    #                         break
    #         if not flag:    # 没有同名文件，repo可能相同也可能不相同，选出相似度最高的文件，计算内容相似度
    #             incorrect_cve_list.append(cve)
        
    #     print(f'{len(cve_list) - len(incorrect_cve_list)} cve correct, {len(incorrect_cve_list)} cve to check by content')
    #     print(f'positive_label_list size: {len(positive_label_list)}')

    #     if os.path.exists(f'{self.codebert_dir}/to_scrapy_list.pkl'):
    #         to_scrapy_list = load_pickle(f'{self.codebert_dir}/to_scrapy_list.pkl')
    #     else:
    #         to_scrapy_list = []
    #         print('start generate to_scrapy_list')
    #         for cve in tqdm.tqdm(incorrect_cve_list):
    #             for repo, sha in self.cve_data_all[cve]['collected_commit']:
    #                 file = ''
    #                 max_simi = 0
    #                 for file_candidate, isdir in self.repo_file_list[repo][sha]:
    #                     if isdir: continue
    #                     file_candidate_lower = file_candidate.lower()
    #                     file_name = file_candidate_lower.split('/')[-1]
    #                     path = '/'.join(file_candidate_lower.split('/')[:-1])
    #                     if not rule_based_filtering(file_name, path):
    #                         continue

    #                     for file_ans in self.cve_data_all[cve]['file_list']:
    #                         file_ans_lower = file_ans.lower()
    #                         simi = difflib.SequenceMatcher(None, file_candidate_lower, file_ans_lower).ratio()
    #                         if simi > max_simi:
    #                             max_simi = simi
    #                             file = file_candidate
    #                 if file:
    #                     to_scrapy_list.append((cve, repo, sha, file))
    #         save_text(f'{self.codebert_dir}/to_scrapy_list', to_scrapy_list)
    #         save_pickle(f'{self.codebert_dir}/to_scrapy_list.pkl', to_scrapy_list)
    #         print(f'end generate to_scrapy_list, size: {len(to_scrapy_list)}')

    #     print('start scrapy to_scrapy_list')
    #     os.makedirs(f'{self.codebert_dir}/candidate_content', exist_ok = True)
    #     self.candidate_content = f'{self.codebert_dir}/candidate_content'
    #     multi_thread(to_scrapy_list, self.get_candidate_content, tokens = github_tokens)
    #     print(f'end scrapy to_scrapy_list')

    #     positive_label_list += self.check_by_file_content(len(cve_list), incorrect_cve_list, self.codebert_dir)
    #     print(f'positive_label_list size: {len(positive_label_list)}')
    #     save_text(f'{self.codebert_dir}/positive_label_list', positive_label_list)
    #     save_pickle(f'{self.codebert_dir}/positive_label_list.pkl', positive_label_list)