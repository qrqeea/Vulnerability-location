import os
import sys
import ast
import tqdm
import random
from util.io_util import *
from util.general_util import *
from util.similarity_util import *
from .ComponentsFilter import ComponentsFilter


class CandidateSelection:

    def __init__(self, module_root_path: str, specified_repo_path: str, cve_data_all: dict, repo_file_list: dict, correct_commits: dict):
        self.module_root_path = module_root_path
        self.specified_repo_path = specified_repo_path
        self.cve_data_all = cve_data_all
        self.repo_file_list = repo_file_list
        self.correct_commits = correct_commits

        os.makedirs(self.module_root_path, exist_ok = True)

        self.components_dir = f'{self.module_root_path}/components'
        os.makedirs(self.components_dir, exist_ok = True)

        self.prompt_components = f'{self.components_dir}/prompt_top10'
        os.makedirs(self.prompt_components, exist_ok = True)

        self.result_components = f'{self.components_dir}/result_top10'
        os.makedirs(self.result_components, exist_ok = True)

        self.full_file_dir = f'{self.module_root_path}/full_file'
        os.makedirs(self.full_file_dir, exist_ok = True)

        self.prompt_full_file = f'{self.full_file_dir}/prompt_top10'
        os.makedirs(self.prompt_full_file, exist_ok = True)

        self.result_full_file = f'{self.full_file_dir}/result_top10'
        os.makedirs(self.result_full_file, exist_ok = True)


    def start(self):
        # self.handle_components()
        self.handle_full_file()
        
    
    def handle_full_file(self):
        # self.get_full_file_candidates()
        self.check_full_file_recall()


    def handle_components(self):
        # componentsFilter = ComponentsFilter(
        #     self.components_dir,
        #     self.specified_repo_path,
        #     self.cve_data_all,
        #     self.repo_file_list,
        #     self.correct_commits
        # )
        # componentsFilter.start()
        # self.get_components_candidates()
        self.check_candidates_recall(load_pickle(f'{self.components_dir}/candidates.pkl'))
    
    
    def get_components_candidates(self):
        def generate_prompt():
            prompt_template = load_file(f'{self.components_dir}/prompt_template')
            filtered_files_list = [
                load_pickle(f'{self.components_dir}/file/filtered_files_0.8.pkl'),
                load_pickle(f'{self.components_dir}/function/filtered_files.pkl'),
                load_pickle(f'{self.components_dir}/module/filtered_files.pkl')
            ]
            type_list = ['file', 'function', 'module']
            for index, filtered_files in enumerate(filtered_files_list):
                component_type = type_list[index]
                for cve, v in filtered_files.items():
                    for repo, files in v.items():
                        if len(files) == 1:     # 一个就不需要选了
                            continue
                        desc = self.cve_data_all[cve]['complete_description'] if 'complete_description' in self.cve_data_all[cve] else self.cve_data_all[cve]['original_description']
                        prompt = prompt_template.replace(
                            '{vulnerability description}', 
                            desc).replace(
                            '{file list}',
                            str(files)
                        )
                        repo_updated = repo.replace('/', '—')
                        save_text(f'{self.prompt_components}/{component_type}__{cve}__{repo_updated}__{len(files)}', prompt)

        # generate_prompt()
        self.prompt_dir = self.prompt_components
        self.result_dir = self.result_components
        # self.count_total_token()

        prompt_files = os.listdir(f'{self.prompt_dir}')
        if '.DS_Store' in prompt_files:
            prompt_files.remove('.DS_Store')
        # multi_thread(prompt_files, self.query_gpt_sub, chunk_size = 400)

        candidates = {}
        for file in os.listdir(self.result_dir):
            if file in ['.DS_Store', 'error_list']:
                continue
            cve = file.split('__')[1]
            repo = file.split('__')[2].replace('—', '/')
            res_path = f'{self.result_dir}/{file}'
            res = load_file(res_path)
            try:
                res = ast.literal_eval(res)
                res = list(set(res))
            except Exception as e:
                with open(res_path, 'r') as f:
                    data = f.readlines()
                    res = [i.strip() for i in data]
            if cve not in candidates:
                candidates[cve] = {}
            candidates[cve][repo] = res     # TODO：格式清洗

        filtered_files = load_pickle(f'{self.components_dir}/filtered_files.pkl')
        for cve, v in filtered_files.items():
            for repo, files in v.items():
                if len(files) != 1:
                    continue
                if cve not in candidates:
                    candidates[cve] = {}
                candidates[cve][repo] = files
        save_json(f'{self.components_dir}/candidates.json', candidates)
        save_pickle(f'{self.components_dir}/candidates.pkl', candidates)


    def query_gpt_sub(self, prompt_files_sub: list):
        for file in tqdm.tqdm(prompt_files_sub):
        # for file in tqdm.tqdm(random.sample(prompt_files_sub, 2)):
            if os.path.exists(f'{self.result_dir}/{file}'):
                continue
            prompt = load_file(f'{self.prompt_dir}/{file}')
            # if calc_token(prompt) > 16385:
            #     continue
            try:
                res = query_openai(prompt, model = 'gpt-4o-2024-05-13')
                save_text(f'{self.result_dir}/{file}', res)
            except Exception as e:
                save_text(f'{self.result_dir}/error_list', f'{file}\n\n{e}', 'a')


    def get_full_file_candidates(self):
        if not os.path.exists(f'{self.full_file_dir}/cve_list.pkl'):
            cve_list_done = list(load_pickle(f'{self.components_dir}/filtered_files.pkl').keys())
            cve_list = [cve
                for cve, v in self.cve_data_all.items()
                if 'collected_commit' in v and cve not in cve_list_done
            ]
            save_text(f'{self.full_file_dir}/cve_list', cve_list)
            save_pickle(f'{self.full_file_dir}/cve_list.pkl', cve_list)
        else:
            cve_list = load_pickle(f'{self.full_file_dir}/cve_list.pkl')

        def generate_prompt():
            os.makedirs(f'{self.prompt_full_file}/file', exist_ok = True)
            os.makedirs(f'{self.prompt_full_file}/dir+file', exist_ok = True)
            os.makedirs(f'{self.result_full_file}/file', exist_ok = True)
            os.makedirs(f'{self.result_full_file}/dir+file', exist_ok = True)

            prompt_file_template = load_file(f'{self.full_file_dir}/prompt_file_template')
            prompt_dir_template = load_file(f'{self.full_file_dir}/prompt_dir_template')
            # 分两种，文件数量小于xxx的给全部文件直接问，剩下的先选dir再选文件
            for cve in tqdm.tqdm(cve_list):
                desc = self.cve_data_all[cve]['complete_description'] if 'complete_description' in self.cve_data_all[cve] else self.cve_data_all[cve]['original_description']
                
                for repo, sha in self.cve_data_all[cve]['collected_commit']:
                    repo_updated = repo.replace('/', '—')
                    files = [
                        file
                        for file, isdir in self.repo_file_list[repo][sha]
                        if not isdir and rule_based_filtering(file)
                    ]
                    if len(files) <= 1000:       # 1000个file以内直接问，如果效果不好就降低数量
                        prompt = prompt_file_template.replace('{vulnerability description}', desc).replace('{file list}', str(files))
                        save_text(f'{self.prompt_full_file}/file/{cve}__{repo_updated}__{len(files)}', prompt)
                        continue
                    continue
                    files = [
                        file
                        for file, isdir in self.repo_file_list[repo][sha]
                        if not isdir and '/' not in file and rule_based_filtering(file)
                    ]
                    dirs = [
                        dir
                        for dir, isdir in self.repo_file_list[repo][sha]
                        if isdir and dir[0] != '.' and not any(item in dir.lower().split('/') for item in ['test', 'docs', 'tests'])
                    ]
                    if len(dirs) < 1 or len(dirs) > 2000 or not files:
                        continue
                    prompt = prompt_template.replace(
                        '{vulnerability description}',
                        self.cve_data_all[cve]['complete_description'] if 'complete_description' in self.cve_data_all[cve] else self.cve_data_all[cve]['original_description']
                        ).replace(
                            '{directory list}',
                            str(dirs)
                        ).replace(
                            '{file list}',
                            str(files)
                        )
                    repo_updated = repo.replace('/', '—')
                    save_text(f'{self.prompt_full_file}/{cve}_{repo_updated}', prompt)
        
        # generate_prompt()
        self.prompt_dir = f'{self.prompt_full_file}/file'
        self.result_dir = f'{self.result_full_file}/file'
        self.count_total_token()
        
        # prompt_files = os.listdir(f'{self.prompt_dir}')
        # if '.DS_Store' in prompt_files:
        #     prompt_files.remove('.DS_Store')
        # multi_thread(prompt_files, self.query_gpt_sub, chunk_size = 500)


    def count_total_token(self):
        total = 0
        for file in tqdm.tqdm(os.listdir(self.prompt_dir)):
            if file in ['.DS_Store']: continue
            token = calc_token(load_file(f'{self.prompt_dir}/{file}'))
            # if token > 16385:
            #     print(file, token)
            total += token
        token_M = int(total / 1000000)
        print(f'total token: {token_M}M, gpt-3 price: {token_M * 0.5}$')
        print(f'total token: {token_M}M, gpt-4 price: {token_M * 5}$')


    def check_candidates_recall(self, candidates: dict):
        candidates = load_pickle(f'{self.components_dir}/candidates.pkl')
        recall = 0
        for cve, v in tqdm.tqdm(candidates.items()):
            f = False
            for repo, files in v.items():
                if not (cve in self.correct_commits and repo in self.correct_commits[cve]):
                    continue
                vul_file = self.correct_commits[cve][repo]
                if len(files) == 1:
                    if files[0] == vul_file:
                        f = True
                else:
                    if any(vul_file.lower() in candidate.lower() or candidate.lower() in vul_file.lower() for candidate in files):
                        f = True
            if f:
                recall += 1
        total_cnt = len(candidates)
        print('{:.2f}%'.format(recall / total_cnt * 100), f'{recall}/{total_cnt})')
        

    def check_full_file_recall(self):
        result_files = os.listdir(self.result_full_file)
        if '.DS_Store' in result_files:
            result_files.remove('.DS_Store')
        correction = {}
        tp = set()
        for file in tqdm.tqdm(result_files):
            cve = file.split('_')[0]
            repo = file[len(cve) + 1:].replace('—', '/')
            if cve not in self.correct_commits or repo not in self.correct_commits[cve]:
                print(333)
                continue
            ans = self.correct_commits[cve][repo]
            res = load_file(f'{self.result_full_file}/{file}')
            try:
                res = ast.literal_eval(res)
            except Exception as e:
                with open(f'{self.result_full_file}/{file}', 'r') as f:
                    data = f.readlines()
                    res = []
                    for i in data:
                        i = i.strip()
                        res.append(i)
                # print(f'error: {e}, {self.result_dir}/{file}')
            if not res:
                print(233)
                continue
            # print(res, ans)
            for dir in res:
                if dir == '/' and '/' not in ans:   # 漏洞文件在根目录下
                    # print(ans)
                    correction[cve] = True
                    continue
                # print(dir, ans[:len(dir)])
                if dir.lower() in ans.lower():
                    correction[cve] = True
            if cve not in correction:
                correction[cve] = False
                if '/' not in ans:
                    tp.add(cve)
                # print(cve, ans, res, '\n')
        # print(correction)
        correct_cnt = 0
        total_count = len(correction)
        for cve, v in correction.items():
            if v:
                correct_cnt += 1
            # else:
            #     print(cve)
        print('{:.2f}%'.format(correct_cnt / total_count * 100), f'({correct_cnt}/{total_count})')
        print('{:.2f}%'.format(correct_cnt / 2397 * 100), f'({correct_cnt}/{2397})')
        # save_text(f'{self.full_file_dir}/cve_list_retry', list(tp))
        # save_pickle(f'{self.full_file_dir}/cve_list_retry.pkl', list(tp))