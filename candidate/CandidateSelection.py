import os
import sys
import csv
import tqdm
import random
import difflib
from util.io_util import *
from util.github_util import github_tokens, get_file_content, get_file_list
from util.similarity_util import *

class CandidateSelection:

    def __init__(self, project_root_path: str, module_root_path: str, cve_data_all: dict, repo_file_list: dict):
        self.project_root_path = project_root_path
        self.module_root_path = module_root_path
        self.cve_data_all = cve_data_all
        self.repo_file_list = repo_file_list

        # 文件名相同
        self.filter_file = [
            'changelog', 'news', 'changes', 'version', 'readme', 'license', 'authors', 'todo', 'history', 'copying', 'relnotes', 'thanks', 'notice', 'whatsnew', 'notes', 'release_notes', 'testlist', 'testsuite', 'test'
        ]
        # 以这些后缀结尾的文件
        self.filter_suffix = [
            '.md', '.txt', '.docx', '.pdf', '.rst', '.changes', '.rdoc', '.mdown',
            '.command', '.out', '.err', '.stderr', '.stdout', '.test',
            '.jpg', '.png', '.svg', '.mp4', '.gif', '.exr',
            '.csv', '.rdf',
            '.ttf', '.otf', '.woff', '.woff2',
            '.mock', '.stub', '.fake',
            '.pptx', '.key',
            '.bak', '.zip', '.gz', '.rar',
            '.gitignore',
            '.lib', '.jpeg', '.ppt', '.xlsx', '.xls', '.doc' '.ico', '.bmp', '.tar.gz', '.tgz', '.css', '.cygport'
        ]
        # 路径中包含
        self.filter_path = [
            'note', 'license', 'test'
        ]
        self.candidate_content_path = f'{self.module_root_path}/candidate_content'
        os.makedirs(self.candidate_content_path, exist_ok = True)

        os.makedirs(self.module_root_path, exist_ok = True)

        self.cve_list_dir = f'{self.module_root_path}/cve_list'
        os.makedirs(self.cve_list_dir, exist_ok = True)


    def start(self):
        res = self.select_by_file_component(1)
        self.check_accuracy_by_repo_and_file_name(res)
        # self.check_accuracy(res, 2)
        # self.check_accuracy(res, 3)
        # self.check_accuracy(res, 4)
        # self.check_accuracy(res, 5)
        # self.check_accuracy(res, 10)
        # self.check_accuracy(res, 50)
        # self.check_accuracy(res, 100)


    def filter_cve_list(self, mode: str):
        file_path = f'{self.cve_list_dir}/cve_list_{mode}'
        if os.path.exists(file_path):
            return load_pickle(f'{file_path}.pkl')
        
        cve_list = []
        type_list = ['Module', 'File', 'Function']
        for cve, v in self.cve_data_all.items():
            components = v.get('components')
            if components and v.get('collected_commit'):
                flag = True
                for index, mask in enumerate(mode):
                    if mask == '0':
                        if components.get(type_list[index]):
                            flag = False
                            break
                    elif mask == '1':
                        if not components.get(type_list[index]):
                            flag = False
                            break
                if flag:
                    cve_list.append(cve)
        
        save_text(file_path, cve_list)
        save_pickle(f'{file_path}.pkl', cve_list)
        return cve_list


    def select_by_file_component(self, k: int, cve_list: list = None, similarity_algorithm = difflib.SequenceMatcher):
        if not cve_list:
            cve_list = self.filter_cve_list('212')  # 212代表必须要有File，Module和Function有没有都行

        res_path = f'{self.module_root_path}/candidates_with_File_component_{len(cve_list)}_{k}_{similarity_algorithm.__name__}.json'
        if os.path.exists(res_path):
            return load_json(res_path)
        
        candidates_100_path = f'{self.module_root_path}/candidates_with_File_component_{len(cve_list)}_100_{similarity_algorithm.__name__}.json'
        if os.path.exists(candidates_100_path):
            candidates_100 = load_json(candidates_100_path)
        else:
            candidates_100 = {}
            for cve in tqdm.tqdm(cve_list):
            # for cve in random.sample(cve_list, 50):
                file_components = self.cve_data_all[cve].get('components').get('File')
                collected_commit = self.cve_data_all[cve].get('collected_commit')

                candidates_100[cve] = {}
                for repo, commit in collected_commit:
                    repo_file_list = self.repo_file_list[repo][commit]
                    related_files = self.find_related_files(file_components, repo_file_list, 100, similarity_algorithm)
                    candidates_100[cve][repo] = related_files
            save_json(candidates_100_path, candidates_100)
        
        print('start reduce data')
        multi_repo_cnt = 0
        multi_candidate_cnt= 0
        reduced_data = {}
        for cve, v in candidates_100.items():
            # if not self.cve_data_all[cve]['collected_repo_correction']: continue
            # if not self.cve_data_all[cve]['collected_commit_correction']: continue
            reduced_data[cve] = {}
            if len(v) > 1:
                multi_repo_cnt += 1
            flag = False
            for repo, triple_list in v.items():
                reduced_data[cve][repo] = []
                for index, triple in enumerate(triple_list):
                    if index >= k and triple[2] != triple_list[index - 1][2]:
                        if index > 1:
                            flag = True
                        break
                    reduced_data[cve][repo].append(triple[1])
            if flag:
                multi_candidate_cnt += 1
        
        print(f'{multi_repo_cnt} cve has multi repo')
        print(f'{multi_candidate_cnt} cve has multi candidate')
        
        save_json(res_path, reduced_data)
        
        print('end reduce data')
        return reduced_data
    
    
    
    def check_accuracy_by_repo_and_file_name(self, data: dict):
        print('start check by repo and file name')
        
        total_count = 0
        correct_cve_list = []
        incorrect_cve_list = []
        for cve, v in data.items():
            total_count += 1
            flag = False
            for repo_candidate, file_candidates in v.items():
                if flag:
                    break
                for repo_ans, file_ans in self.cve_data_all[cve]['repo_and_file']:
                    # if repo_candidate == repo_ans and file_ans in file_candidates:
                    if any(file_ans.lower() in file_candidate.lower() or file_candidate.lower() in file_ans.lower() for file_candidate in file_candidates):
                        flag = True
                        break
            if flag:
                correct_cve_list.append(cve)
            else:
                incorrect_cve_list.append(cve)
        print(f'{len(correct_cve_list)}/{total_count}, acc: {len(correct_cve_list) / total_count}')
        print('end check by repo and file name')

        return incorrect_cve_list


    def check_accuracy(self, data: dict):
        print('start check accuracy')
        
        incorrect_cve_list = self.check_accuracy_by_repo_and_file_name(data)
        gt_content_table = self.get_gt_file_content(incorrect_cve_list)
        
        # print('start generate to_scrapy_list')
        # to_scrapy_list = []
        # for cve in incorrect_cve_list:
        #     if cve not in gt_content_table: continue
        #     for repo_candidate, file_candidates in reduced_data[cve].items():
        #         sha = ''
        #         for (repo_1, sha_1) in self.cve_data_all[cve]['collected_commit']:
        #             if repo_1 == repo_candidate:
        #                 sha = sha_1
        #                 break
        #         if sha == '':
        #             print('error, sha')
        #             sys.exit()
        #         for file_candidate in file_candidates:
        #             to_scrapy_list.append((cve, repo_candidate, sha, file_candidate))
        # print('end generate to_scrapy_list')

        # print('start scrapy to_scrapy_list')
        # def get_candidate_content(to_scrapy_list_sub: list, token: str):
        #     for cve, repo, sha, file in tqdm.tqdm(to_scrapy_list_sub):
        #         path = f'{cve}_{repo}_{file}'.replace('/', '—')
        #         path = f'{self.candidate_content_path}/{path}'
        #         if os.path.exists(path):
        #             continue
        #         res = get_file_content(repo, sha, file, token)
        #         if res:
        #             save_text(path, res)
        
        # multi_thread(to_scrapy_list, get_candidate_content, tokens = github_tokens)
        # print('end scrapy to_scrapy_list')
        
        print('start check by content')
        for cve in incorrect_cve_list.copy():
            if cve not in gt_content_table: continue
            ans_list = []
            for repo_ans, file_ans in self.cve_data_all[cve]['repo_and_file']:
                if repo_ans not in gt_content_table[cve]: continue
                for sha, v in gt_content_table[cve][repo_ans].items():
                    if file_ans not in v: continue
                    ans_list.append((repo_ans, file_ans, v[file_ans]))
            # for item in ans_list:
            #     print(item[0], item[1], item[2][:50])
            flag = False
            for repo_candidate, file_candidates in tqdm.tqdm(data[cve].items()):
                if flag: break
                for file_candidate in file_candidates:
                    path = f'{cve}_{repo_candidate}_{file_candidate}'.replace('/', '—')
                    path = f'{self.candidate_content_path}/{path}'
                    if not os.path.exists(path): continue
                    candidate_content = load_file(path)
                    for repo_ans, file_ans, content in ans_list:
                        simi = difflib.SequenceMatcher(None, content, candidate_content).ratio()
                        if simi > 0.8:
                            print(cve, repo_candidate, file_candidate, repo_ans, file_ans, simi)
                            flag = True
                            break
            if flag:
                incorrect_cve_list.remove(cve)
        
        correct_cnt = len(data) - len(incorrect_cve_list)
        print(f'{len(correct_cnt)}/{len(data)}, acc: {correct_cnt / len(data)}')
        print('end check by content')

        # save_text('/Volumes/Data/experiment_data/candidate/incorrrect_cve_list', incorrect_cve_list)
        # save_pickle('/Volumes/Data/experiment_data/candidate/incorrrect_cve_list.pkl', incorrect_cve_list)


    def find_related_files(self, keywords: list, files: list, k: int, similarity_algorithm):
        # components中包含/则匹配完整路径，否则只匹配文件名
        res = []
        for keyword in keywords:
            for file, isdir in files:
                if isdir: continue
                file_lower = file.lower()
                keyword_lower = keyword.lower()
                path = '/'.join(file_lower.split('/')[:-1])
                if any(file_lower.split('/')[-1] == item for item in self.filter_file): continue
                if any(file_lower.endswith(suffix) for suffix in self.filter_suffix): continue
                if any(item in path for item in self.filter_path): continue

                if '/' not in keyword:
                    keyword_lower = keyword.split('/')[-1]
                    file_lower = file.split('/')[-1]
                
                if similarity_algorithm.__name__ == 'SequenceMatcher':
                    similarity = difflib.SequenceMatcher(None, keyword_lower, file_lower).ratio()
                elif similarity_algorithm.__name__ == 'ngram_similarity':
                    similarity = ngram_similarity(keyword_lower, file_lower, 2)
                else:
                    similarity = similarity_algorithm(keyword_lower, file_lower)
                res.append((keyword, file, similarity))
        sorted_res = sorted(res, key = lambda x: x[2], reverse = (similarity_algorithm.__name__ != 'levenshtein_distance'))
        # sorted_res = sorted(res, key = lambda x: x[2])
        return sorted_res[:k]
    

    def get_gt_file_content(self, cve_list: list):
        if os.path.exists('/Volumes/Data/experiment_data/ground_truth/gt_content_table.pkl'):
            return load_pickle('/Volumes/Data/experiment_data/ground_truth/gt_content_table.pkl')

        def check_repo_sha_existence(cve_list_sub: list, token: str):
            for cve in tqdm.tqdm(cve_list_sub):
                if cve not in possible_shas: continue

                for sha in possible_shas[cve]:
                    for repo in self.cve_data_all[cve]['repos']:
                        if get_file_list(repo, sha, token):    # (repo, sha)存在
                            if cve not in gt_content_table:
                                gt_content_table[cve] = {}
                            if repo not in gt_content_table[cve]:
                                gt_content_table[cve][repo] = {}
                            gt_content_table[cve][repo][sha] = {}

        def get_file_content_sub(cve_list_sub: list, token: str):
            for cve in tqdm.tqdm(cve_list_sub):
                if cve not in gt_content_table: continue
                for repo, file in self.cve_data_all[cve]['repo_and_file']:
                    if repo not in gt_content_table[cve]: continue

                    for sha in gt_content_table[cve][repo]:
                        res = get_file_content(repo, sha, file, token)
                        if res:
                            gt_content_table[cve][repo][sha][file] = res


        possible_shas = load_json('/Volumes/Data/experiment_data/ground_truth/cve_possible_shas.json')
        
        if os.path.exists('/Volumes/Data/experiment_data/ground_truth/gt_content_table.pkl'):
            gt_content_table = load_pickle('/Volumes/Data/experiment_data/ground_truth/gt_content_table.pkl')
        else:
            gt_content_table = {}
            multi_thread(cve_list, check_repo_sha_existence, tokens = github_tokens)
        
        multi_thread(cve_list, get_file_content_sub, tokens = github_tokens)

        save_json('/Volumes/Data/experiment_data/ground_truth/gt_content_table.json', gt_content_table)
        save_pickle('/Volumes/Data/experiment_data/ground_truth/gt_content_table.pkl', gt_content_table)
        
        return gt_content_table