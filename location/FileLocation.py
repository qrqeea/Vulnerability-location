import os
import sys
import csv
import ast
import tqdm
import random
import pandas as pd
from util.io_util import *
from util.general_util import *
from util.similarity_util import *

# language_map = {
    # 'c': 'location/extract_code/c.js'
    # 'cpp': 'location/extract_code/cpp.js',
    # 'java': 'location/extract_code/java.js',
    # 'js': 'location/extract_code/js.js',
# }

class FileLocation:

    def __init__(self, module_root_path: str, repo_path: str, cve_data_all: dict, candidates: dict):
        self.module_root_path = module_root_path
        self.repo_path = repo_path
        self.cve_data_all = cve_data_all
        self.candidates = candidates

        os.makedirs(self.module_root_path, exist_ok = True)

        self.prompt_dir = f'{self.module_root_path}/prompt'
        os.makedirs(self.prompt_dir, exist_ok = True)

        self.result_dir = f'{self.module_root_path}/result'
        os.makedirs(self.result_dir, exist_ok = True)

        self.cve_list = list(candidates.keys())
        print(len(self.cve_list))
        save_text(f'{self.module_root_path}/cve_list', self.cve_list)
        save_pickle(f'{self.module_root_path}/cve_list.pkl', self.cve_list)


    def start(self):
        # self.split_file_content()
        # self.text_to_vector()
        # self.calc_similarity()
        
        # self.count_file_cnt()
        # self.generate_prompt()
        # self.count_total_tokens()
        # self.query_gpt()
        self.check_result()     # TODO: 有一些文件乱码，如CVE-2022-23584

    
    def split_file_content(self, block_max_token = 2048):
        for cve, files in tqdm.tqdm(self.candidates.items()):
            repo = self.cve_data_all[cve]['collected_commit'][0].replace('/', '—')
            path = f'{self.repo_path}/{cve}/{repo}'
            if not os.path.exists(path):
                print(cve, repo, 'not exist')
                continue
            df = pd.DataFrame({
                'file': [],
                'token_len': [],
                'text': []
            })
            for file in files:
                if not os.path.exists(f'{path}/{file}'):
                    print(cve, repo, file, 'not found')
                    continue
                try:
                    content = load_file(f'{path}/{file}')
                    text_len = len(content)
                    token_len = calc_token(content)
                    if token_len > block_max_token:
                        block_size = math.ceil(token_len / block_max_token)
                        block_len = int(text_len / block_size)
                        l = 0
                        for i in range(1, block_size):
                            r = block_len * i
                            while r > l and calc_token(content[l:r]) > block_max_token:
                                r -= 50
                            if content[l:r]:
                                df.loc[len(df)] = [
                                    file,
                                    f'{calc_token(content[l:r])}/{token_len}',
                                    content[l:r]
                                ]
                            l = r
                        if content[l:]:
                            df.loc[len(df)] = [
                                file,
                                f'{calc_token(content[l:])}/{token_len}',
                                content[l:]
                            ]
                    else:
                        df.loc[len(df)] = [file, f'{token_len}/{token_len}', content]
                except Exception as e:
                    print(cve, repo, file, 'load failure', e)
                    continue
            df.to_csv(
                f'{self.embedding_text}/{cve}.csv',
                index = False,
                quotechar = '"',
                quoting = csv.QUOTE_ALL
            )


    def text_to_vector(self):
        
        def get_embedding(text: str):
            return client.embeddings.create(input = [text], model = 'text-embedding-3-small').data[0].embedding     

        load_dotenv()
        client = OpenAI()

        def text_to_vector_sub(cve_list_sub: list):
            # for cve in tqdm.tqdm(cve_list_sub):
            for cve in tqdm.tqdm(random.sample(cve_list_sub, 1)):
                target_path = f'{self.embedding_result}/{cve}.csv'
                if os.path.exists(target_path):
                    continue

                df = pd.read_csv(f'{self.embedding_text}/{cve}.csv')
                df['vector'] = df.text.apply(lambda x: get_embedding(x))
                df.to_csv(
                    target_path,
                    index = False, 
                    quotechar = '"',
                    quoting = csv.QUOTE_ALL
                )

        rest_cve = list(
            {file.split('.')[0] for file in os.listdir(self.embedding_text) if file not in ['.DS_Store']} -
            {file.split('.')[0] for file in os.listdir(self.embedding_result) if file not in ['.DS_Store']}
        )
        print(len(rest_cve))

        print('start embedding')
        multi_thread(rest_cve, text_to_vector_sub, chunk_size = 10)
        print('end embedding')


    def calc_similarity(self):
        print('start calc similarity')

        df_query = pd.read_csv('/Volumes/NVD/experiment_data/completion/query_embedding_result.csv')
        tp = {}
        for _, row in df_query.iterrows():
            tp[row.cve] = ast.literal_eval(row.vector)

        for file in tqdm.tqdm(os.listdir(self.embedding_result)):
            if file in ['.DS_Store']: continue
            
            cve = file.split('.')[0]
            df = pd.read_csv(f'{self.embedding_result}/{cve}.csv')
            if len(df.columns) == 5:
                continue
            if cve not in tp:
                continue
            query_vector = tp[cve]
            
            df['similarity'] = df.vector.apply(lambda x: cosine_similarity(ast.literal_eval(x), query_vector))
            df = df.sort_values('similarity', ascending = False)
            df.to_csv(
                f'{self.embedding_result}/{cve}.csv',
                index = False, 
                quotechar = '"',
                quoting = csv.QUOTE_ALL
            )
        print('end calc similarity')


    def generate_prompt(self):
        prompt_template = load_file(f'{self.module_root_path}/prompt_location_vul_file')
        for cve, files in tqdm.tqdm(self.candidates.items()):
            repo = self.cve_data_all[cve]['collected_commit'][0].replace('/', '—')
            path = f'{self.repo_path}/{cve}/{repo}'
            if not os.path.exists(path):
                print('error', cve, repo, 'not exist')
                continue
            # index = 1
            tp = ''
            for file in files:
                try:
                    content = load_file(f'{path}/{file}')
                    content = format_text(clear_comment(content), ' ')
                    tp += f'file name: "{file}"\nfile content: {content}\n\n'
                except Exception as e:
                    print('error', cve, repo, file, e)
                    continue
                # index += 1
            if not tp:
                print('233', cve)
                continue
            prompt = prompt_template.replace(
                '{description}',
                self.cve_data_all[cve]['complete_description'] if 'complete_description' in self.cve_data_all[cve] else self.cve_data_all[cve]['original_description']
            ).replace('{files}', tp)
            save_text(f'{self.prompt_dir}/{cve}', prompt)


    def count_total_tokens(self):
        cve_list_done = {
            cve for cve in os.listdir(f'{self.result_dir}')
            if cve not in ['.DS_Store', 'error_list']
        }
        cve_list = list(set(self.cve_list) - cve_list_done)
        print(f'rest cve list size: {len(cve_list)}')

        tokens = 0
        for cve in tqdm.tqdm(cve_list):
            prompt = load_file(f'{self.prompt_dir}/{cve}')
            token = calc_token(prompt, model = 'gpt-4-turbo')
            if token > 128000:
                continue
            tokens += token
        token_M = int(tokens / 1000000)
        print(f'total token: {token_M}M, price: {token_M * 5}$')


    def query_gpt(self):
        cve_list_done = {
            cve for cve in os.listdir(f'{self.result_dir}')
            if cve not in ['.DS_Store', 'error_list']
        }
        cve_list = list(set(self.cve_list) - cve_list_done)
        print(f'rest cve list size: {len(cve_list)}')

        def query_gpt_sub(cve_list_sub: list):
            # for cve in tqdm.tqdm(random.sample(cve_list_sub, 3)):
            for cve in tqdm.tqdm(cve_list_sub):
                if os.path.exists(f'{self.result_dir}/{cve}'):
                    continue
                prompt = load_file(f'{self.prompt_dir}/{cve}')
                token = calc_token(prompt, model = 'gpt-4-turbo')
                if token > 128000:
                    continue
                try:
                    res = query_openai(prompt, model = 'gpt-4o-2024-05-13')
                    save_text(f'{self.result_dir}/{cve}', res)
                except Exception as e:
                    save_text(f'{self.result_dir}/error_list', f'{cve}\n\n{e}', 'a')

        multi_thread(cve_list, query_gpt_sub, chunk_size = 380)


    def check_result(self):
        token_too_large_cnt = 55
        correct_cnt_1 = token_too_large_cnt
        correct_cnt_2 = token_too_large_cnt
        correct_cnt_3 = token_too_large_cnt
        correct_cnt_5 = token_too_large_cnt
        total_cnt = token_too_large_cnt
        rank_list = {}
        for cve in os.listdir(f'{self.result_dir}'):
            if cve in ['.DS_Store', 'error_list']:
                continue
            with open(f'{self.result_dir}/{cve}', 'r') as f:
                gtp_res = f.readlines()
            res = []
            tp = set()
            try:
                for file in gtp_res:
                    if any(item in file for item in ['```', '[', ']']):
                        continue
                    file = file.strip()
                    if '- ' in file:
                        file = file[2:]
                    elif file[0].isdigit():
                        l = file.find('. ')
                        file = file[l + 2:]
                    if file[:11] == 'file name: ':
                        file = file[11:]
                    file = file.replace('",', '')
                    file = file.replace('"', '')
                    if file not in tp:
                        res.append(file)
                    tp.add(file)
                # print(res)
                rank_list[cve] = res
                total_cnt += 1
                ans = self.cve_data_all[cve]['collected_commit'][2]
                if ans in res[:1]:
                    correct_cnt_1 += 1
                    correct_cnt_2 += 1
                    correct_cnt_3 += 1
                    correct_cnt_5 += 1
                elif ans in res[:2]:
                    correct_cnt_2 += 1
                    correct_cnt_3 += 1
                    correct_cnt_5 += 1
                elif ans in res[:3]:
                    correct_cnt_3 += 1
                    correct_cnt_5 += 1
                elif ans in res[:5]:
                    correct_cnt_5 += 1
                # else:
                # elif ans not in res:
                #     # copy_file(f'{self.prompt_dir}/{cve}', f'{self.module_root_path}/prompt_test/{cve}')
                #     # print(cve)
                #     # print(f'https://nvd.nist.gov/vuln/detail/{cve}')
                #     print('gpt_res:', res)
                #     print('candidates:', self.candidates[cve])
                #     print('ans:', self.cve_data_all[cve]['collected_commit'][2])
                #     # print(self.candidates[cve])
                #     print(f'{self.prompt_dir}/{cve}')
                #     print(f'{self.result_dir}/{cve}')
                #     print('________________________________________________')
            except Exception as e:
                print('error:', f'{self.result_dir}/{cve}')
                continue
        print('{:.2f}%'.format(correct_cnt_1 / total_cnt * 100), f'({correct_cnt_1}/{total_cnt})')
        print('{:.2f}%'.format(correct_cnt_2 / total_cnt * 100), f'({correct_cnt_2}/{total_cnt})')
        print('{:.2f}%'.format(correct_cnt_3 / total_cnt * 100), f'({correct_cnt_3}/{total_cnt})')
        print('{:.2f}%'.format(correct_cnt_5 / total_cnt * 100), f'({correct_cnt_5}/{total_cnt})')
        
        save_json(f'{self.module_root_path}/rank_list.json', rank_list)
        save_pickle(f'{self.module_root_path}/rank_list.pkl', rank_list)


    def count_file_cnt(self):
        size_list = []
        cnt = 0
        for cve, files in self.candidates.items():
            size_list.append(len(files))
            cnt += len(files)
        print(cnt)
        print(count_range(size_list, [1, 2, 5, 10, 20, 50, 100, 200, 300, 350, 380]))


    # def extract_candidate_files(self):
    #     for cve, files  in tqdm.tqdm(self.candidates.items()):
    #         repo = self.cve_data_all[cve]['collected_commit'][0].replace('/', '—')
    #         path = f'{self.repo_path}/{cve}/{repo}'
    #         if not os.path.exists(path):
    #             print(cve, repo, 'not exist')
    #             continue
    #         dir = f'{self.extract_result_dir}/{cve}'
    #         os.makedirs(dir, exist_ok = True)
    #         for file in files:
    #             if os.path.exists(f'{path}/{file}'):
    #                 try:
    #                     suffix = file.split('/')[-1].split('.')[-1].lower()
    #                     if suffix in language_map:
    #                         js_script = language_map[suffix]
    #                         command = ['node', js_script, f'{path}/{file}']
    #                         print(command)
    #                         result = subprocess.run(command, capture_output = True, text = True)
    #                         tp = file.replace('/', '\\')
    #                         save_path = f'{self.extract_result_dir}/{cve}/{tp}'
    #                         save_text(save_path, result.stdout)
    #                         print(f'{path}/{file}')
    #                         sys.exit()
    #                     else:       # 使用文件原始内容
    #                         pass
    #                 except Exception as e:
    #                     print(f'load {path}/{file} failure', e)
    #             else:
    #                 print(cve, repo, file, 'not exist')