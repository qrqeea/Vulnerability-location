import requests
from bs4 import BeautifulSoup
from util import format_text


def scrapy(url: str):
    if 'security' in url:
        # 也许要改成'/security/'
        return scrapy_security(url)
    elif 'issue' in url:
        return scrapy_issue(url)
    else:
        # 其他类型的网页主要是代码变更，没有直接与漏洞相关的信息
        return None


def scrapy_security(url: str):

    res = ''
    soup = BeautifulSoup(requests.get(url).text, 'html.parser')

    info = soup.find(name = 'h1', attrs = {
        'class' : 'gh-header-title',
    })
    if info != None:
        # print(handleText(info.text))
        res += 'Title:\n' + format_text(info.text) + '\n\n'

    info = soup.find(name = 'div', attrs = {
        'class' : 'Bow-row border-0 clearfix',
    })
    if info != None:
        # print(handleText(info.text))
        res += '{Package}:\n' + format_text(info.text) + '\n\n'

    info = soup.find(name = 'div', attrs = {
        'class' : 'markdown-body comment-body p-0',
    })
    if info != None:
        # print(handleText(info.text))
        res += 'Description:\n' + format_text(info.text)
    
    return res


def scrapy_issue(url: str):

    res = ''
    soup = BeautifulSoup(requests.get(url).text, 'html.parser')

    info = soup.find(name = 'bdi', attrs = {
        'class' : 'js-issue-title markdown-title',
    })
    if info != None:
        # print(handleText(info.text))
        res += 'Title:\n' + format_text(info.text) + '\n\n'

    info = soup.find(name = 'div', attrs = {
        'class' : 'js-discussion',
    })
    if info != None:
        # print(handleText(info.text))
        res += 'Content:\n' + format_text(info.text) + '\n'

    return res


if __name__ == '__main__':
    url = 'https://github.com/Admidio/admidio/issues/908'
    res = scrapy(url)
    print(res)