from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


def scrapy(url: str):

    res = ''

    driver = webdriver.Chrome()
    driver.get(url)

    element = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, 'row'))
    )

    # content = driver.page_source
    # print(content)

    content = driver.find_elements(By.CLASS_NAME, 'card')
    if len(content) > 2:
        res += content[0].text
        res += content[-2].text

    driver.quit()

    return res


if __name__ == '__main__':
    url = 'https://www.exploit-db.com/exploits/46488'
    res = scrapy(url)
    print(res)