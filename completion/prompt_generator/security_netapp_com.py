import re
import requests
from bs4 import BeautifulSoup

def handleText(input):
    # 以换行符为分隔符，将字符串分割成行
    lines = input.split('\n')

    # 去除每行前后的空格，并过滤掉空行
    stripped_lines = [line.strip() for line in lines if line.strip()]

    # 将处理后的内容合并为一个字符串
    result = '\n'.join(stripped_lines)
    return result

def generate_prompt(url: str):

    prompt = '''
I will give you some information about the content of posts discussing software vulnerabilities. The information includes these parts: title, overview, affected products, remediation and revision history, followed by {Title},{Overview}, {Affected Products}, {Remediation} and {Revision History} respectively. You need to extract the valuable parts from the information. The focus is on the information section describing the vulnerability.\n\n'''[1:]

    res = requests.get(url)
    soup = BeautifulSoup(res.text, 'html.parser')

    info = soup.find(name = 'div', attrs = {
        'class' : 'luci-long-form-text',
    })
    if info != None:
        try:
            # print(handleText(info.h2.text))
            prompt += '{Title}:\n' + handleText(info.h2.text) + '\n\n'
        except Exception as e:
            pass
        
    info = soup.findAll(name = 'div', attrs = {
        'class' : 'n-tabs__content',
    })
    titles = ['{Overview}:\n', '{Affected Products}:\n', '{Remediation}:\n', '{Revision History}:\n']
    if info != None:
        for index, item in enumerate(info):
            # print(handleText(item.text))
            prompt += titles[index] + handleText(item.text) + '\n\n'

    return prompt

if __name__ == '__main__':
    url = 'https://security.netapp.com/advisory/ntap-20190910-0003/'
    prompt = generate_prompt(url)
    if prompt != None:
        with open('./prompt_template/prompt_test/security.netapp.com', 'w') as f:
            print(prompt, file = f)