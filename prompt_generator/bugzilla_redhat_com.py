import re
import requests
from bs4 import BeautifulSoup

def generate_prompt(url: str):

    prompt = '''
I will give you some information about the content of posts discussing software vulnerabilities. The information includes these parts: title, attributes and comments, followed by {Title}, {Attributes} and {Comments} respectively. You need to extract the valuable parts from the information. The focus is on the information section describing the vulnerability.\n\n'''[1:]

    res = requests.get(url)
    soup = BeautifulSoup(res.text, 'html.parser')

    info = soup.find(name = 'span', attrs = {
        'id' : 'short_desc_nonedit_display',
    })
    if info != None:
        # print(info.text)
        prompt += '{Title}:\n' + info.text + '\n\n'

    info = soup.find(name = 'table', attrs = {
        'class' : 'edit_form',
    })
    if info != None:
        # print(re.sub(r'\n\s*\n', '\n', info.text))
        prompt += '{Attributes}:' + re.sub(r'\n\s*\n', '\n', info.text) + '\n\n'

    info = soup.find(name = 'div', attrs = {
        'id' : 'comments',
    })
    if info != None:
        # print(re.sub(r'\n\s*\n', '\n', info.text))
        prompt += '{Comments}:' + re.sub(r'\n\s*\n', '\n', info.text)
    
    return prompt

if __name__ == '__main__':
    url = 'https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2019-10141'
    prompt = generate_prompt(url)
    if prompt != None:
        with open('./prompt_template/prompt_test/bugzilla.redhat.com', 'w') as f:
            print(prompt, file = f)