import requests
from bs4 import BeautifulSoup

def handleText(input):
    # 以换行符为分隔符，将字符串分割成行
    lines = input.split('\n')

    # 去除每行前后的空格，并过滤掉空行
    stripped_lines = [line.strip() for line in lines if line.strip()]

    # 将处理后的内容合并为一个字符串
    result = '\n'.join(stripped_lines)
    return result

def generate_prompt(url: str):
    if 'security' in url:
        # 也许要改成'/security/'
        return generate_prompt_security(url)
    elif 'issue' in url:
        return generate_prompt_issue(url)
    else:
        # 其他类型的网页主要是代码变更，没有直接与漏洞相关的信息
        return None


def generate_prompt_security(url: str):

    prompt = '''
I will give you some information about a software vulnerability. The information includes these parts: title, package and description, followed by {Title}, {Package} and {Description} respectively. Note that some parts may not exist. You need to extract the valuable parts from the information. The focus is on the information section describing the vulnerability.\n\n'''[1:]

    res = requests.get(url)
    soup = BeautifulSoup(res.text, 'html.parser')

    info = soup.find(name = 'h1', attrs = {
        'class' : 'gh-header-title',
    })
    if info != None:
        # print(handleText(info.text))
        prompt += '{Title}:\n' + handleText(info.text) + '\n\n'

    info = soup.find(name = 'div', attrs = {
        'class' : 'Bow-row border-0 clearfix',
    })
    if info != None:
        # print(handleText(info.text))
        prompt += '{Package}:\n' + handleText(info.text) + '\n\n'

    info = soup.find(name = 'div', attrs = {
        'class' : 'markdown-body comment-body p-0',
    })
    if info != None:
        # print(handleText(info.text))
        prompt += '{Description}:\n' + handleText(info.text)
    
    return prompt

def generate_prompt_issue(url: str):

    prompt = '''
I will give you some information about the content of posts discussing software vulnerabilities. The information includes these parts: title and content, followed by {Title} and {Content} respectively. You need to extract the valuable parts from the information. The focus is on the information section describing the vulnerability. If the content section contains insufficient information to extract valuable details about the vulnerability, the output should be "no results".\n\n'''[1:]

    res = requests.get(url)
    soup = BeautifulSoup(res.text, 'html.parser')

    info = soup.find(name = 'bdi', attrs = {
        'class' : 'js-issue-title markdown-title',
    })
    if info != None:
        # print(handleText(info.text))
        prompt += '{Title}:\n' + handleText(info.text) + '\n\n'

    info = soup.find(name = 'div', attrs = {
        'class' : 'js-discussion',
    })
    if info != None:
        # print(handleText(info.text))
        prompt += '{Content}:\n' + handleText(info.text) + '\n'
    
    prompt += '''
Atenetion: If the content section contains insufficient information to extract valuable details about the vulnerability, the output should be "no results". Do not output redundant prompt information, only output "no results".'''

    return prompt

if __name__ == '__main__':
    url = 'https://github.com/Admidio/admidio/issues/908'
    prompt = generate_prompt(url)
    if prompt != None:
        with open('./prompt_template/prompt_test/github.com', 'w') as f:
            print(prompt, file = f)