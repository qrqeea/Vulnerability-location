import os
import re
import sys
import json
import tqdm
import time
import pytz
import random
import requests
from datetime import datetime
from get_cpe_product import get_cpe_product
from util import *
from common.github_util import *


class RepositoryCollection:

    def __init__(self, root_path: str, cve_json_path: str, cve_list: list):
        self.root_path = root_path
        self.cve_json_path = cve_json_path
        self.cve_list = cve_list

        self.repo_query_gpt = f'{self.root_path}/repo_query_gpt'
        if not os.path.exists(self.repo_query_gpt):
            os.mkdir(self.repo_query_gpt)

        self.procedure_data = f'{self.root_path}/procedure_data'
        if not os.path.exists(self.repo_query_gpt):
            os.mkdir(self.repo_query_gpt)

        self.reference_url_res = 'repo_from_reference_url'
        self.gpt_3_res = 'repo_from_gpt3'
        self.gpt_4_res = 'repo_from_gpt4'
        self.github_res = 'repo_from_github_search'


    def start(self):
        target = self.reference_url_res
        self.search_reference_url(target)
        self.check_result(
            load_pickle(f'{self.procedure_data}/{target}.pkl'),
            f'{target}_incorrect'
        )

        target = self.gpt_3_res
        self.query_gpt('gpt-3.5-turbo-0125', target)
        self.check_result(
            load_pickle(f'{self.procedure_data}/{target}.pkl'),
            f'{target}_incorrect'
        )

        target = self.gpt_4_res
        self.query_gpt('gpt-4-turbo', target)
        self.check_result(
            load_pickle(f'{self.procedure_data}/{target}.pkl'),
            f'{target}_incorrect'
        )

        target = self.github_res
        self.search_from_github(target)
        self.check_result(
            load_pickle(f'{self.procedure_data}/{target}.pkl'),
            f'{target}_incorrect'
        )

        self.union_result()


    def search_reference_url(self, target: str):
        # 搜索cve的reference url, 如果有github url则提取repo
        print('start search reference url')
        res = {}
        for cve in tqdm.tqdm(self.cve_list):
            filePath = f'{self.cve_json_path}/{cve}.json'
            reference_list = [dic['url'] for dic in load_json(filePath)['containers']['cna']['references']]
            for url in reference_list:
                if get_domain(url) == 'github.com':
                    repo_full_name = '/'.join(url.split('/')[3:5])
                    if '#' in repo_full_name:
                        repo_full_name = repo_full_name[:repo_full_name.find('#')]
                    if cve in res.keys():
                        res[cve].add(repo_full_name)
                    else:
                        res[cve] = {repo_full_name}
        print(f'found {len(res)}/{len(self.cve_list)}, {len(self.cve_list) - len(res)} rest')
        print('end search reference url\n')

        def check_repo(cve_sub_list: list, token: str):
            for cve in tqdm.tqdm(cve_sub_list):
                repo_to_delete = []
                for repo in res[cve]:
                    if not check_repo_exist(repo, token):
                        repo_to_delete.append(repo)
                        # print('error', cve, repo)
                
                for repo in repo_to_delete:
                    res[cve].remove(repo)
                if not res[cve]:
                    del res[cve]
                    # print('del', cve)

        # 检查提取到的repo是否存在
        print('start check if the repo exists')
        cve_get_repo_from_url = list(res.keys())
        multi_thread(cve_get_repo_from_url, check_repo, tokens = github_tokens)

        save_text(f'{self.procedure_data}/{target}', res)
        save_pickle(f'{self.procedure_data}/{target}.pkl', res)
        
        print(f'found {len(res)}/{len(self.cve_list)}, {len(self.cve_list) - len(res)} rest')
        print('end check if the repo exists')


    def check_result(self, data: dict, target: str):
        print('start check repo')
        ground_truth = {}
        for cve, repo in load_pickle('/Volumes/NVD/experiment_data/all/cleaned_gt_commit_single_v2.pkl'):
            if cve in ground_truth.keys():
                ground_truth[cve].append(repo.lower())
            else:
                ground_truth[cve] = [repo.lower()]
        incorrect_cve_dic = {}

        for cve, repos in tqdm.tqdm(data.items()):
            flag = False
            for repo in repos:
                if repo.lower() in ground_truth[cve]:
                    flag = True
                    break
            if not flag:      
                incorrect_cve_dic[cve] = repos
        print(f'first check: {len(incorrect_cve_dic)} cve incorrect')
        
        # 检查是否是改过名的或fork的repo
        def check_repo_name(cve_list: list, token: str):
            for cve in tqdm.tqdm(cve_list):
                for repo in incorrect_cve_dic[cve]:
                    latest_repo_name = get_latest_repo_name(repo, token).lower()
                    ground_truth[cve] = [get_latest_repo_name(repo, token).lower() for repo in ground_truth[cve]]
                    if latest_repo_name in ground_truth[cve]:
                        del incorrect_cve_dic[cve]
                        break
                    original_repo_name = get_original_repo_name(repo, token).lower()
                    ground_truth[cve] = [get_original_repo_name(repo, token).lower() for repo in ground_truth[cve]]
                    if original_repo_name in ground_truth[cve]:
                        del incorrect_cve_dic[cve]
                        break

        incorrect_cve_list = [cve for cve, _ in incorrect_cve_dic.items()]
        multi_thread(incorrect_cve_list, check_repo_name, tokens = github_tokens)

        if incorrect_cve_dic:
            save_text(f'{self.procedure_data}/{target}', incorrect_cve_dic)
            save_pickle(f'{self.procedure_data}/{target}.pkl', incorrect_cve_dic)
        
        print('accuracy: {:.2f}%,'.format((len(data) - len(incorrect_cve_dic)) / len(data) * 100), 
              f'{len(incorrect_cve_dic)} rest')
        print('end check repo')


    def search_from_github(self, target: str):

        def search(product_list_sub: list, token: str):
            for product in tqdm.tqdm(product_list_sub):
                tp = set()
                try:
                    params = {'q': product, 'per_page': 1}
                    search_res = search_repo(params, token)
                    tp |= search_res
                    # params = {'q': product, 'per_page': 5, 'sort': 'forks'}
                    # search_res = search_repo(params, token)
                    # tp |= search_res
                    # params = {'q': product, 'per_page': 5, 'sort': 'stars'}
                    # search_res = search_repo(params, token)
                    # tp |= search_res
                except Exception as e:
                    # print('token:', token)
                    print(e)
                product_search_res[product] = tp
        
        print('start search github')
        cpe_product_path = f'{self.root_path}/cpe_product.pkl'
        if os.path.exists(cpe_product_path):
            cpe_product = load_pickle(cpe_product_path)
        else:
            cpe_product = get_cpe_product(rest_cve_list, '/Volumes/NVD/experiment_data/all/cpe_json')
            save_pickle(cpe_product_path, cpe_product)
        
        rest_cve_list = list(
            set(self.cve_list) - set(load_pickle(f'{self.procedure_data}/{self.reference_url_res}.pkl').keys()) - 
            set(load_pickle(f'{self.procedure_data}/{self.gpt_3_res}.pkl').keys()) -
            set(load_pickle(f'{self.procedure_data}/{self.gpt_4_res}.pkl').keys())
        )
        print(len(rest_cve_list))

        product_list = list({ product for cve in rest_cve_list for product in cpe_product[cve] })
        print(len(product_list))
        
        res = {}
        product_search_res = {}

        multi_thread(product_list, search, tokens = github_tokens)
        
        for cve in rest_cve_list:
            res[cve] = set()
            for product in cpe_product[cve]:
                res[cve] |= product_search_res[product]

        save_text(f'{self.procedure_data}/{target}', res)
        save_pickle(f'{self.procedure_data}/{target}.pkl', res)

        print(f'found {len(res)}/{len(rest_cve_list)}, {len(rest_cve_list) - len(res)} rest')
        print('end search github\n')


    def query_gpt(self, model: str, target: str):
        print('start query gpt')

        # rest_cve_list = list(set(self.cve_list) - set(load_pickle(f'{self.procedure_data}/{self.reference_url_res}.pkl').keys()))
        # print(len(rest_cve_list))

        rest_cve_list = list(
            set(self.cve_list) - set(load_pickle(f'{self.procedure_data}/{self.reference_url_res}.pkl').keys())
        )
        if model == 'gpt-4-turbo':
            rest_cve_list = list(
            set(rest_cve_list) - set(load_pickle(f'{self.procedure_data}/{self.gpt_3_res}.pkl').keys())
        )
        print(len(rest_cve_list))

        # rest_cve_list = ['CVE-2017-2801', 'CVE-2019-11278', 'CVE-2021-3933', 'CVE-2019-1003003', 'CVE-2019-12617']
        # rest_cve_list = list(random.sample(rest_cve_list, 5))
        # print(rest_cve_list)
        
        cpe_uri = load_pickle('/Volumes/NVD/experiment_data/datasets/repository/cpe_uri.pkl')
        # cpe_product = load_pickle('/Volumes/NVD/experiment_data/datasets/repository/cpe_product.pkl')

        with open(f'{self.root_path}/prompt_query_repo', 'r') as f:
            prompt_general = f.read()
        
        res = {}

        def query(cve_list_sub: list):
            for cve in tqdm.tqdm(cve_list_sub):
                res_path = f'{self.repo_query_gpt}/{cve}_res'
                if os.path.exists(res_path):
                    with open(res_path, 'r') as f:
                        url = f.read().strip()
                        repo_full_name = self.extract_repo_name(url)
                    if repo_full_name and requests.get(url).ok:
                        res[cve] = {repo_full_name}
                    # print('skip')
                    continue

                prompt = prompt_general.replace('{cve}', f'{cve}')
                prompt = prompt.replace('{cpe}', f'{next(iter(cpe_uri[cve]))}')
                save_text(f'{self.repo_query_gpt}/{cve}_prompt', prompt)
                try:
                    url = query_openai(prompt, model = model)
                    save_text(f'{self.repo_query_gpt}/{cve}_res', url)
                    repo_full_name = self.extract_repo_name(url)
                    if repo_full_name and requests.get(url).ok:
                        res[cve] = {repo_full_name}
                    else:
                        save_text(f'{self.repo_query_gpt}/incorrect_list', cve, 'a')
                except Exception as e:
                    save_text(f'{self.repo_query_gpt}/exception_list', f'{cve}\n{e}\n', 'a')

        multi_thread(rest_cve_list, query, chunk_size = 100)

        if res:
            save_text(f'{self.procedure_data}/{target}', res)
            save_pickle(f'{self.procedure_data}/{target}.pkl', res)

        print(f'get {len(res)}/{len(rest_cve_list)}, {len(rest_cve_list) - len(res)} rest')
        print('end query gpt\n')


    def extract_repo_name(self, repo_url):
        if repo_url.startswith('https://github.com/'):
            path_components: list = repo_url[len('https://github.com/'):].split('/')
            path_components = [item for item in path_components if item != '']  # 去除空元素

            if len(path_components) >= 2:
                return f"{path_components[0]}/{path_components[1]}"
        return None


    def union_result(self):
        file_list = [self.reference_url_res, self.gpt_3_res, self.gpt_4_res, self.github_res]
        res = {}
        for file in file_list:
            full_path = f'{self.procedure_data}/{file}.pkl'
            data = load_pickle(full_path)
            # print(len(data))
            res.update(data)
        # print(len(res))
        save_text(f'{self.root_path}/repo_collection', res)
        save_pickle(f'{self.root_path}/repo_collection.pkl', res)

        # self.check_result(res, 'repo_collection_incorrect')


if __name__ == '__main__':
    cve_list = load_pickle('/Volumes/NVD/experiment_data/267/procedure_data/cve_list_267.pkl')