import os
import re
import sys
import json
import tqdm
import time
import pytz
import random
import requests
from datetime import datetime
from get_cpe_product import get_cpe_product
from util import *
from common.github_util import *


class RepositoryCollection:

    def __init__(self, root_path: str, cve_json_path: str, cve_list: list):
        self.root_path = root_path
        self.cve_json_path = cve_json_path
        self.cve_list = cve_list

        self.reference_url_res = 'repo_from_reference_url'
        self.gpt_res = 'repo_from_gpt'
        self.github_res = 'repo_from_github_search'

        self.repo_query_gpt = f'{self.root_path}/repo_query_gpt'
        if not os.path.exists(self.repo_query_gpt):
            os.mkdir(self.repo_query_gpt)


    def start(self):
        # target = self.reference_url_res
        # self.search_reference_url(target)
        # self.check_result(
        #     load_pickle(f'{self.root_path}/{target}.pkl'),
        #     f'{target}_incorrect'
        # )

        target = self.gpt_res
        self.query_gpt(target)
        self.check_result(
            load_pickle(f'{self.root_path}/{target}.pkl'),
            f'{target}_incorrect'
        )

        # target = self.github_res
        # self.search_from_github(target)
        # self.check_result(
        #     load_pickle(f'{self.root_path}/{target}.pkl'),
        #     f'{target}_incorrect'
        # )


    def search_reference_url(self, target: str):
        # 搜索cve的reference url, 如果有github url则提取repo
        print('start search reference url')
        res = {}
        for cve in tqdm.tqdm(self.cve_list):
            filePath = f'{self.cve_json_path}/{cve}.json'
            reference_list = [dic['url'] for dic in load_json(filePath)['containers']['cna']['references']]
            for url in reference_list:
                if get_domain(url) == 'github.com':
                    repo_full_name = '/'.join(url.split('/')[3:5])
                    if cve in res.keys():
                        res[cve].add(repo_full_name)
                    else:
                        res[cve] = {repo_full_name}
        print(f'found {len(res)}/{len(self.cve_list)}, {len(self.cve_list) - len(res)} rest')
        print('end search reference url\n')

        def check_repo(cve_sub_list: list, token: str):
            for cve in tqdm.tqdm(cve_sub_list):
                repo_to_delete = []
                for repo in res[cve]:
                    if not check_repo_exist(repo, token):
                        repo_to_delete.append(repo)
                        # print('error', cve, repo)
                
                for repo in repo_to_delete:
                    res[cve].remove(repo)
                if not res[cve]:
                    del res[cve]
                    # print('del', cve)

        # 检查提取到的repo是否存在
        print('start check if the repo exists')
        cve_get_repo_from_url = list(res.keys())
        multi_thread(cve_get_repo_from_url, check_repo, tokens = github_tokens)

        save_text(f'{self.root_path}/{target}', res)
        save_pickle(f'{self.root_path}/{target}.pkl', res)
        
        print(f'found {len(res)}/{len(self.cve_list)}, {len(self.cve_list) - len(res)} rest')
        print('end check if the repo exists')


    def check_result(self, data: dict, target: str):
        print('start check repo')
        ground_truth = {}
        for cve, repo in load_pickle('/Volumes/NVD/experiment_data/all/cleaned_gt_commit_single_v2.pkl'):
            if cve in ground_truth.keys():
                ground_truth[cve].append(repo.lower())
            else:
                ground_truth[cve] = [repo.lower()]
        incorrect_cve_dic = {}

        for cve, repos in tqdm.tqdm(data.items()):
            flag = False
            for repo in repos:
                if repo.lower() in ground_truth[cve]:
                    flag = True
                    break
            if not flag:      
                incorrect_cve_dic[cve] = repos
        print(f'first check: {len(incorrect_cve_dic)} cve incorrect')
        
        # 检查是否是改过名的或fork的repo
        def check_repo_name(cve_list: list, token: str):
            for cve in tqdm.tqdm(cve_list):
                for repo in incorrect_cve_dic[cve]:
                    latest_repo_name = get_latest_repo_name(repo, token).lower()
                    ground_truth[cve] = [get_latest_repo_name(repo, token).lower() for repo in ground_truth[cve]]
                    if latest_repo_name in ground_truth[cve]:
                        del incorrect_cve_dic[cve]
                        break
                    original_repo_name = get_original_repo_name(repo, token).lower()
                    ground_truth[cve] = [get_original_repo_name(repo, token).lower() for repo in ground_truth[cve]]
                    if original_repo_name in ground_truth[cve]:
                        del incorrect_cve_dic[cve]
                        break

        incorrect_cve_list = [cve for cve, _ in incorrect_cve_dic.items()]
        multi_thread(incorrect_cve_list, check_repo_name, tokens = github_tokens)

        if incorrect_cve_dic:
            save_text(f'{self.root_path}/{target}', incorrect_cve_dic)
            save_pickle(f'{self.root_path}/{target}.pkl', incorrect_cve_dic)
        
        print('accuracy: {:.2f}%,'.format((len(data) - len(incorrect_cve_dic)) / len(data) * 100), 
              f'{len(incorrect_cve_dic)} rest')
        print('end check repo')


    def search_from_github(self, target: str):
        rest_cve_list = load_pickle(f'{self.root_path}/cve_after_search_reference_url.pkl')
        # rest_cve_list = list(set(self.cve_list) - set(load_pickle(f'{self.root_path}/{self.gpt_res}.pkl').keys()))
        print(len(rest_cve_list))
            
        def search(cve_list_sub: list, token: str):
            for cve in tqdm.tqdm(cve_list_sub):
                tp = set()
                for product in cpe_product[cve]:
                    try:
                        params = {'q': product, 'per_page': 3}
                        # params = {'q': product, 'per_page': 10, 'sort': 'stars'}
                        # params = {'q': product, 'per_page': 10, 'sort': 'forks'}
                        search_res = search_repo(params, token)
                        tp = tp.union(search_res)
                    except Exception as e:
                        # print('token:', token)
                        print(e)
                res[cve] = tp

        print('start search github')

        res = {}
        cpe_product_path = f'{self.root_path}/cpe_product.pkl'
        if os.path.exists(cpe_product_path):
            cpe_product = load_pickle(cpe_product_path)
        else:
            cpe_product = get_cpe_product(rest_cve_list, '/Volumes/NVD/experiment_data/all/cpe_json')
            save_pickle(cpe_product_path, cpe_product)

        multi_thread(rest_cve_list, search, tokens = github_tokens)

        save_text(f'{self.root_path}/{target}', res)
        save_pickle(f'{self.root_path}/{target}.pkl', res)

        print(f'found {len(res)}/{len(rest_cve_list)}, {len(rest_cve_list) - len(res)} rest')
        print('end search github\n')


    def query_gpt(self, target: str):
        print('start query gpt')

        rest_cve_list = list(set(self.cve_list) - set(load_pickle(f'{self.root_path}/{self.reference_url_res}.pkl').keys()))
        print(len(rest_cve_list))

        # rest_cve_list = ['CVE-2017-2801', 'CVE-2019-11278', 'CVE-2021-3933', 'CVE-2019-1003003', 'CVE-2019-12617']
        # rest_cve_list = list(random.sample(rest_cve_list, 5))
        # print(rest_cve_list)
        
        cpe_uri = load_pickle('/Volumes/NVD/experiment_data/datasets/repository/cpe_uri.pkl')
        # cpe_product = load_pickle('/Volumes/NVD/experiment_data/datasets/repository/cpe_product.pkl')

        with open(f'{self.root_path}/prompt_query_repo', 'r') as f:
            prompt_general = f.read()
        
        res = {}
        for cve in tqdm.tqdm(rest_cve_list):
            res_path = f'{self.repo_query_gpt}/{cve}_res'
            if os.path.exists(res_path):
                with open(res_path, 'r') as f:
                    url = f.read().strip()
                    repo_full_name = extract_repo_name(url)
                if repo_full_name and requests.get(url).ok:
                    res[cve] = [repo_full_name]
                print('skip')
                continue

            prompt = prompt_general.replace('{cve}', f'{cve}')
            prompt = prompt.replace('{cpe}', f'{next(iter(cpe_uri[cve]))}')
            save_text(f'{self.repo_query_gpt}/{cve}_prompt', prompt)
            try:
                url = query_openai(prompt)    # 'gpt-4-turbo'
                save_text(f'{self.repo_query_gpt}/{cve}_res', url)
                repo_full_name = extract_repo_name(url)
                if repo_full_name and requests.get(url).ok:
                    res[cve] = [repo_full_name]
                else:
                    save_text(f'{self.repo_query_gpt}/incorrect_list', cve, 'a')
            except Exception as e:
                save_text(f'{self.repo_query_gpt}/exception_list', f'{cve}\n{e}\n', 'a')

        if res:
            save_text(f'{self.root_path}/{target}', res)
            save_pickle(f'{self.root_path}/{target}.pkl', res)

        print(f'get {len(res)}/{len(rest_cve_list)}, {len(rest_cve_list) - len(res)} rest')
        print('end query gpt\n')


def extract_repo_name(repo_url):
    if repo_url.startswith("https://github.com/"):
        path_components: list = repo_url[len("https://github.com/"):].split('/')
        path_components = [item for item in path_components if item != '']  # 去除空元素

        if len(path_components) >= 2:
            return f"{path_components[0]}/{path_components[1]}"
    return None


if __name__ == '__main__':
    cve_list = load_pickle('/Volumes/NVD/experiment_data/267/procedure_data/cve_list_267.pkl')