import os
import re
import sys
import json
import tqdm
import time
import pytz
import requests
from datetime import datetime
from get_cpe_product import get_cpe
from util import *
from common.github_util import *


class RepositoryCollection:

    def __init__(self, root_path: str, cve_json_path: str, cve_list: list):
        self.root_path = root_path
        self.cve_json_path = cve_json_path
        self.cve_list = cve_list


    def start(self):
        self.search_reference_url()
        self.check_reference_url_result()

        # self.search_from_github()
        # self.check_github_search_result()


    def search_reference_url(self):
        # 搜索cve的reference url, 如果有github url则提取repo
        print('start search reference url')
        res = {}
        for cve in tqdm.tqdm(self.cve_list):
            filePath = f'{self.cve_json_path}/{cve}.json'
            reference_list = [dic['url'] for dic in load_json(filePath)['containers']['cna']['references']]
            for url in reference_list:
                if get_domain(url) == 'github.com':
                    repo_full_name = '/'.join(url.split('/')[3:5])
                    if cve in res.keys():
                        res[cve].add(repo_full_name)
                    else:
                        res[cve] = {repo_full_name}
        print(f'found {len(res)}/{len(self.cve_list)}, {len(self.cve_list) - len(res)} rest')
        print('end search reference url\n')

        def check_repo(cve_sub_list: list, token: str):
            for cve in tqdm.tqdm(cve_sub_list):
                repo_to_delete = []
                for repo in res[cve]:
                    if not check_repo_exist(repo, token):
                        repo_to_delete.append(repo)
                        # print('error', cve, repo)
                
                for repo in repo_to_delete:
                    res[cve].remove(repo)
                if not res[cve]:
                    del res[cve]
                    # print('del', cve)

        # 检查提取到的repo是否存在
        print('start check if the repo exists')
        cve_get_repo_from_url = list(res.keys())
        multi_thread(cve_get_repo_from_url, check_repo, tokens = github_tokens)
        print(f'found {len(res)}/{len(self.cve_list)}, {len(self.cve_list) - len(res)} rest')
        print('end check if the repo exists')

        rest_cve_list = list(set(self.cve_list) - set(res.keys()))
        save_text(f'{self.root_path}/repo_from_reference_url', res)
        save_pickle(f'{self.root_path}/repo_from_reference_url.pkl', res)
        save_text(f'{self.root_path}/cve_after_search_reference_url', rest_cve_list)
        save_pickle(f'{self.root_path}/cve_after_search_reference_url.pkl', rest_cve_list)


    def check_reference_url_result(self):
        print('start check repo from reference url')
        data = load_pickle(f'{self.root_path}/repo_from_reference_url.pkl')
        ground_truth = {}
        for cve, repo in load_pickle('/Volumes/NVD/experiment_data/all/cleaned_gt_commit_single_v2.pkl'):
            if cve in ground_truth.keys():
                ground_truth[cve].append(repo.lower())
            else:
                ground_truth[cve] = [repo.lower()]
        incorrect_cve_dic = {}

        for cve, repos in tqdm.tqdm(data.items()):
            flag = False
            for repo in repos:
                if repo.lower() in ground_truth[cve]:
                    flag = True
                    break
            if not flag:      
                incorrect_cve_dic[cve] = repos
        print(f'first check: {len(incorrect_cve_dic)} cve incorrect')
        
        # 检查是否是改过名的或fork的repo
        def check_repo_name(cve_list: list, token: str):
            for cve in tqdm.tqdm(cve_list):
                for repo in incorrect_cve_dic[cve]:
                    latest_repo_name = get_latest_repo_name(repo, token).lower()
                    ground_truth[cve] = [get_latest_repo_name(repo, token).lower() for repo in ground_truth[cve]]
                    if latest_repo_name in ground_truth[cve]:
                        del incorrect_cve_dic[cve]
                        break
                    original_repo_name = get_original_repo_name(repo, token).lower()
                    ground_truth[cve] = [get_original_repo_name(repo, token).lower() for repo in ground_truth[cve]]
                    if original_repo_name in ground_truth[cve]:
                        del incorrect_cve_dic[cve]
                        break

        incorrect_cve_list = [cve for cve, _ in incorrect_cve_dic.items()]
        multi_thread(incorrect_cve_list, check_repo_name, tokens = github_tokens)

        save_text(f'{self.root_path}/incorrect_repo_from_reference_url', incorrect_cve_dic)
        save_pickle(f'{self.root_path}/incorrect_repo_from_reference_url.pkl', incorrect_cve_dic)
        print('accuracy: {:.2f}%,'.format((len(data) - len(incorrect_cve_dic)) / len(data) * 100), 
              f'{len(incorrect_cve_dic)} rest')
        print('end check repo from reference url')
        

    def check_github_search_result(self):
        print('start check repo from github search')
        data = load_pickle(f'{self.root_path}/repo_from_github_search.pkl')
        ground_truth = load_pickle('/Volumes/NVD/experiment_data/all/cleaned_gt_commit_single_v2.pkl').keys()
        ground_truth = {(cve, repo.lower()) for (cve, repo) in ground_truth}
        res = []
        for cve, repos in data.items():
            flag = False
            for repo in repos:
                if (cve, repo.lower()) in ground_truth:
                    flag = True
                    break
            if not flag:
                res.append((cve, [repo for repo in repos]))
        save_text(f'{self.root_path}/incorrect_repo_from_github_search', res)
        correct_count = len(data) - len(res)
        print(f'accuracy: {correct_count}/{len(data)}, ', '{:.2f}%,'.format(correct_count / len(data) * 100), f'{len(res)} rest')
        print('end check repo from github search\n')


    def search_from_github(self):
        rest_cve_list = load_pickle(f'{self.root_path}/cve_after_search_reference_url.pkl')
        url = 'https://api.github.com/search/repositories'

        def check_api_limit(headers):
            remaining = headers['X-RateLimit-Remaining']
            reset_time = int(headers['X-RateLimit-Reset'])
            if int(remaining) == 0:
                reset_time_utc = datetime.utcfromtimestamp(reset_time)
                beijing_timezone = pytz.timezone('Asia/Shanghai')
                reset_time_beijing = reset_time_utc.replace(tzinfo=pytz.utc).astimezone(beijing_timezone)
                now_beijing = datetime.now(beijing_timezone)
                time_to_reset = (reset_time_beijing - now_beijing).total_seconds() + 2
                # print(f'剩余重置时间：{time_to_reset} seconds')
                if time_to_reset < 0:
                    time_to_reset = 1
                time.sleep(time_to_reset)
            
        def search(cve_list_sub: list, token: str):
            headers = {'Authorization': f'token {token}'}
            for cve in tqdm.tqdm(cve_list_sub):
                tp = set()
                for product in cpe_product[cve]:
                    try:
                        # params = {'q': product, 'per_page': 10, 'sort': 'forks'}
                        # response = requests.get(url, headers = headers, params = params)
                        # if response.ok:
                        #     data = response.json()
                        #     repositories = data["items"]
                        #     # repo["html_url"]
                        #     tp = tp.union({repo['full_name'] for repo in repositories})
                        #     check_api_limit(response.headers)

                        # params = {'q': product, 'per_page': 10, 'sort': 'stars'}
                        # response = requests.get(url, headers = headers, params = params)
                        # if response.ok:
                        #     data = response.json()
                        #     repositories = data["items"]
                        #     tp = tp.union({repo['full_name'] for repo in repositories})
                        #     check_api_limit(response.headers)

                        params = {'q': product, 'per_page': 2}
                        response = requests.get(url, headers = headers, params = params)
                        if response.ok:
                            data = response.json()
                            repositories = data["items"]
                            tp = tp.union({repo['full_name'] for repo in repositories})
                            check_api_limit(response.headers)
                        else:
                            # print('token:', token)
                            print(response.text)
                            # check_api_limit(response.headers)
                    except Exception as e:
                        # print('token:', token)
                        print(e)
                res[cve] = tp

        print('start search github')

        res = {}
        cpe_product_path = f'{self.root_path}/cpe_product.pkl'
        if os.path.exists(cpe_product_path):
            cpe_product = load_pickle(cpe_product_path)
        else:
            cpe_product = get_cpe(rest_cve_list, '/Volumes/NVD/experiment_data/all/cpe_json')
            save_pickle(cpe_product_path, cpe_product)

        multi_thread(rest_cve_list, search, tokens = github_tokens)

        save_text(f'{self.root_path}/repo_from_github_search', res)
        save_pickle(f'{self.root_path}/repo_from_github_search.pkl', res)

        print(f'found {len(res)}/{len(rest_cve_list)}, {len(rest_cve_list) - len(res)} rest')
        print('end search github\n')


def extract_repo_name(repo_url):
    if repo_url.startswith("https://github.com/"):
        path_components: list = repo_url[len("https://github.com/"):].split('/')
        path_components = [item for item in path_components if item != '']  # 去除空元素
        # 如果路径包含用户名和仓库名，则认为是仓库地址
        if len(path_components) >= 2:
            return f"{path_components[0]}/{path_components[1]}"
    return None


def get_product_url(cpe_product_dic: dict):
    products = set()
    for _, value in cpe_product_dic.items():
        products |= value
    # print(len(products))
        
    prompt_general = 'Give me the GitHub URL of #, answer within 100 tokens. Only output the URL, do not output prompt information.'
    product_repo_url = {}    # {product: [(repo_full_name, repo_url)]}
    
    tmp_file = 'repository_tmp.pkl'
    if os.path.exists(tmp_file):
        product_repo_url = load_pickle(tmp_file)
        print(len(product_repo_url))

    for product in tqdm.tqdm(products):
        if product_repo_url.get(product):
            continue

        prompt = prompt_general.replace('#', product)
        # print(prompt)
        try:
            # print('querying openai')
            url = query_openai(prompt, 'gpt-4-turbo')
            repo_full_name = extract_repo_name(url)
            if repo_full_name and requests.get(url).ok:
                product_repo_url[product] = [(repo_full_name, url)]
            else:
                urls = search_github_repositories(product)
                if urls:
                    tp = []
                    for url in urls:
                        repo_full_name = extract_repo_name(url)
                        if repo_full_name and requests.get(url).ok:
                            tp.append((repo_full_name, url))
                    product_repo_url[product] = tp
        except Exception:
            try:
                # print('second querying openai')
                url = query_openai(prompt)
                repo_full_name = extract_repo_name(url)
                if repo_full_name and requests.get(url).ok:
                    product_repo_url[product] = [(repo_full_name, url)]
                else:
                    urls = search_github_repositories(product)
                    if urls:
                        tp = []
                        for url in urls:
                            repo_full_name = extract_repo_name(url)
                            if repo_full_name and requests.get(url).ok:
                                tp.append((repo_full_name, url))
                        product_repo_url[product] = tp
            except Exception as e:
                # print(e)
                save_pickle(tmp_file, product_repo_url)

    return product_repo_url


def get_repository_by_product(cpe_product_dic: dict):
    # input: {cve: {cpe_products}}
    # 汇总所有product，依次询问gpt，然后验证是否有效，若无效通过github搜索，保留5个，{product: [(repo_full_name, repo_url)]}
    # 汇总输出：遍历input，对每个product，到2中查找，若存在，则输出{(cve, repo_full_name): url}
    
    product_repo_url = get_product_url(cpe_product_dic)
    # print(product_repo_url)
    res = {}
    for cve, products in cpe_product_dic.items():
        for product in products:
            if product_repo_url.get(product):
                for repo_full_name, url in product_repo_url[product]:
                    res[(cve, repo_full_name)] = url
    return res


def get_repository(cve_list: list, target_path: str):
    if os.path.exists(target_path):
        return load_pickle(f'{target_path}.pkl')

    cve_repo, cve_product = get_cpe_products(
        cve_list,
        '/Volumes/NVD/experiment_data/all/cpe_json'
    )
    
    # cve_product = {
    #     'CVE-2021-21996' :  {'salt'},
    #     'CVE-2021-22119' :  {'spring_security'},
    #     'CVE-2021-22696' :  {'cxf'},
    #     'CVE-2021-23450' :  {'dojo'},
    #     'CVE-2016-9459' :  {'owncloud', 'nextcloud_server'},
    #     'CVE-2016-9460' :  {'owncloud', 'nextcloud'}
    # }

    res = get_repository_by_product(cve_product)
    for cve, full_repo_name_set in cve_repo.items():
        for full_repo_name in full_repo_name_set:
            res[(cve, full_repo_name)] = 'https://github.com/' + full_repo_name
    
    save_text(target_path, res)
    save_pickle(f'{target_path}.pkl', res)

    return res


if __name__ == '__main__':
    cve_list = load_pickle('/Volumes/NVD/experiment_data/267/procedure_data/cve_list_267.pkl')
    get_repository(
        cve_list,
        '/Volumes/NVD/experiment_data/267/procedure_data/{(cve, repo_full_name): url}'
    )