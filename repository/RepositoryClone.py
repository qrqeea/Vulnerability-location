import os
import tqdm
import random
from util.io_util import *
from util.github_util import *


class RepositoryClone:

    def __init__(self, module_root_path: str, repo_data_path: str, cve_data_all: dict, cve_list: list):
        self.module_root_path = module_root_path
        self.repo_data_path = repo_data_path
        self.cve_data_all = cve_data_all
        self.cve_list = cve_list

        os.makedirs(self.module_root_path, exist_ok = True)

        self.cloned_repo_dir = f'{self.module_root_path}/repo_all'
        os.makedirs(self.cloned_repo_dir, exist_ok = True)

        self.target_dir = f'{self.module_root_path}/target'
        os.makedirs(self.target_dir, exist_ok = True)


    def start(self):
        # self.clone_all_repo()
        self.clone_specified_repo()
        # repo_file_list = self.clone_specified_repo_file_list()
        # error_list = self.verify_specified_repo(repo_file_list)
        # self.clone_specified_repo(error_list)

    
    def clone_all_repo(self):
        repo_all = {
            repo
            for cve in self.cve_list
            for repo in self.cve_data_all[cve]['collected_repo']
        }
        print(len(repo_all))        # 1801

        for repo_full_name in tqdm.tqdm(repo_all):
            # print(repo_full_name)
            repo_full_name_updated = repo_full_name.replace('/', '—')
            # print(repo_full_name_updated)

            dest_dir = f'{self.cloned_repo_dir}/{repo_full_name_updated}'
            if os.path.exists(dest_dir):
                continue
            # cmd = f'git clone --depth=1 {url}.git {path}/{repo_full_name_updated}'
            cmd = f'git clone --depth=1 git@github.com:{repo_full_name}.git {dest_dir}'
            if os.system(cmd) != 0:
                save_text(f'{self.cloned_repo_dir}/error_list', repo_full_name, 'a')

    
    def clone_specified_repo(self):

        def clone_specified_repo_sub(repo_list_sub: dict):
            for repo in tqdm.tqdm(repo_list_sub):
                for (cve, sha) in rest_specified_repo_dic[repo]:
                    dir_name = f'{self.target_dir}/{cve}'
                    # print('dir_name:', dir_name)
                    os.makedirs(dir_name, exist_ok = True)

                    repo_full_name_updated = repo.replace('/', '—')
                    dest_path_repo = f'{dir_name}/{repo_full_name_updated}'

                    if os.path.exists(dest_path_repo):
                        continue
                    #     print('start delete original data')
                    #     shutil.rmtree(dest_path_repo)
                    #     print('end delete original data')
                        
                    source_path_repo = f'{self.cloned_repo_dir}/{repo_full_name_updated}'

                    cmd1 = f'cd {source_path_repo} && git fetch origin {sha} --depth=1 1>/dev/null'
                    # cmd2 = f'cd {source_path_repo} && git clean -fd && git checkout . 1>/dev/null'
                    cmd2 = f'cd {source_path_repo} && git clean -fd 1>/dev/null'
                    cmd3 = f'cd {source_path_repo} && git checkout {sha} 1>/dev/null'
                    print('run cmd1')
                    if os.system(cmd1) != 0:
                        save_text(f'{self.target_dir}/error_list', f'cmd1, {cve}, {repo}', 'a')
                        print('cmd1 error')
                        continue
                    print('run cmd2')
                    if os.system(cmd2) != 0:
                        save_text(f'{self.target_dir}/error_list', f'cmd2, {cve}, {repo}', 'a')
                        print('cmd2 error')
                        continue
                    print('run cmd3')
                    if os.system(cmd3) != 0:
                        save_text(f'{self.target_dir}/error_list', f'cmd3, {cve}, {repo}', 'a')
                        print('cmd3 error')
                        continue

                    if not os.path.exists(dest_path_repo):
                        os.mkdir(dest_path_repo)

                    cmd = f"rsync -a --exclude='.git' {source_path_repo} {dir_name}"
                    
                    print('run cmd4')
                    if os.system(cmd) != 0:
                        save_text(f'{self.target_dir}/error_list', f'cmd4, {cve}, {repo}', 'a')
                        print('cmd4 error')
        
        if not os.path.exists(f'{self.module_root_path}/rest_specified_repo_dic.pkl'):
            cnt_done = 0
            cnt_rest = 0
            rest_specified_repo_dic = {}
            for cve in tqdm.tqdm(self.cve_list):
                for repo, sha in self.cve_data_all[cve]['collected_commit']:
                    repo_full_name_updated = repo.replace('/', '—')
                    if os.path.exists(f'{self.target_dir}/{cve}/{repo_full_name_updated}'):
                        cnt_done += 1
                        continue
                    if repo not in rest_specified_repo_dic:
                        rest_specified_repo_dic[repo] = []
                    rest_specified_repo_dic[repo].append((cve, sha))
                    cnt_rest += 1
            print(f'already copy {cnt_done} repo')
            print(f'rest cnt: {cnt_rest}')
            save_text(f'{self.module_root_path}/rest_specified_repo_dic', rest_specified_repo_dic)
            save_pickle(f'{self.module_root_path}/rest_specified_repo_dic.pkl', rest_specified_repo_dic)
        else:
            rest_specified_repo_dic = load_pickle(f'{self.module_root_path}/rest_specified_repo_dic.pkl')
        
        repos = list(rest_specified_repo_dic.keys())
        print(len(repos))
        # p1 = repos[:500]
        # p2 = repos[500:]
        # save_text('repository/p1', p1)
        # save_pickle('repository/p1.pkl', p1)
        # save_text('repository/p2', p2)
        # save_pickle('repository/p2.pkl', p2)
            
        multi_thread(repos, clone_specified_repo_sub, chunk_size = 500)
        

    def clone_specified_repo_file_list(self):

        def clone_specified_repo_file_list_sub(to_scrapy_list_sub: list, token: str):
            for (repo, sha) in tqdm.tqdm(to_scrapy_list_sub):
                if repo not in repo_file_list:
                    repo_file_list[repo] = {}
                if sha not in repo_file_list[repo]:
                    repo_file_list[repo][sha] = get_file_list(repo, sha, token)
            
        path = f'{self.repo_data_path}/repo_file_list'
        repo_file_list = load_pickle(f'{path}.pkl') if os.path.exists(f'{path}.pkl') else {}

        to_scrapy_list = list({
            (repo, sha)
            for cve in self.cve_list
            for repo, sha in self.cve_data_all[cve]['collected_commit']
            if not (repo in repo_file_list and sha in repo_file_list[repo])
        })
        print('to_scrapy_list size:', len(to_scrapy_list))

        if to_scrapy_list:
            multi_thread(to_scrapy_list, clone_specified_repo_file_list_sub, tokens = github_tokens)
            save_json(f'{path}.json', repo_file_list)
            save_pickle(f'{path}.pkl', repo_file_list)

        return repo_file_list


    def verify_specified_repo(self, repo_file_list: dict):
        total_count = 0
        error_count = 0
        error_list = []
        for cve in tqdm.tqdm(self.cve_list):
            for repo, sha in self.cve_data_all[cve]['collected_commit']:
                repo_updated = repo.replace('/', '—')
                path = f'{self.target_dir}/{cve}/{repo_updated}'
                if not os.path.exists(path):
                    # save_text(f'{self.module_root_path}/error_list', f'{cve} {repo} not exist', 'a')
                    # error_list.append((cve, repo, sha))
                    # error_count += 1
                    continue
                total_count += 1
                for file_path, _ in repo_file_list[repo][sha]:
                    if not os.path.islink(file_path) and not os.path.exists(f'{path}/{file_path}'):
                        error_list.append((cve, repo, sha))
                        # save_text(f'{self.module_root_path}/error_list', f'{path}/{file_path} not exist', 'a')
                        error_count += 1
                        break
        print(f'total_count: {total_count}, error_count: {error_count}')

        save_text(f'{self.module_root_path}/specified_repo_error_list', error_list)
        save_pickle(f'{self.module_root_path}/specified_repo_error_list.pkl', error_list)
        return error_list