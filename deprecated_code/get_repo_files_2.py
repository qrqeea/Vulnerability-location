import os
import sys
import tqdm
import time
import threading
from github import Github
from util.io_util import load_pickle, save_pickle, save_text

def get_file_name(cve_and_commit: dict, idx: int, token: str):
    
    def parse_file_names(tree, repo):
        store = []
        file_store = []
        for one_tree in tree.tree:
            try:
                if one_tree.type == 'tree':

                    try:
                        rate_limit = g.get_rate_limit()
                        remaining = rate_limit.raw_data['core']['remaining']
                        reset = rate_limit.raw_data['core']['reset']
                        if remaining <= 5:
                            timestamp = time.time()
                            wait_second = int(reset - timestamp)
                            if wait_second <= 0:
                                continue
                            print('wait ', wait_second)
                            time.sleep(wait_second + 2)
                    except:
                        print('abnormal no limit')
                        time.sleep(60)
                    tree_sha = one_tree.sha
                    sub_trees = repo.get_git_tree(tree_sha)
                    tmp_store, tmp_file = parse_file_names(sub_trees, repo)
                    store += [one_tree.path + '/' + one_subtree for one_subtree in tmp_store]
                    file_store += tmp_file
                else:
                    store.append(one_tree.path)
                    file_store.append(one_tree.sha)
            except (Exception, KeyboardInterrupt) as e:
                if hasattr(e, 'status') and e.status == 403:
                    time.sleep(2)
                print(e)
        return store, file_store


    g = Github(token)
    store_dict = {}
    
    tmp_file = f'tmp/second/mid/file_name_{idx}.pkl'
    if os.path.exists(tmp_file):
        store_dict = load_pickle(tmp_file)
        # print(len(store))
        # print(store.keys())

    for cve_and_repo, commit in tqdm.tqdm(cve_and_commit.items()):
        if store_dict.get(cve_and_repo):
            continue
        repo_full_name = cve_and_repo[1]
        sha = commit[0]
        try:
            try:
                rate_limit = g.get_rate_limit()
                remaining = rate_limit.raw_data['core']['remaining']
                reset = rate_limit.raw_data['core']['reset']
                if remaining <= 5:
                    timestamp = time.time()
                    wait_second = int(reset - timestamp)
                    if wait_second <= 0:
                        continue
                    print('wait ', wait_second)
                    time.sleep(wait_second + 2)
            except:
                print('abnormal no limit')
                time.sleep(60)

            repo = g.get_repo(full_name_or_id = repo_full_name)

            try:
                rate_limit = g.get_rate_limit()
                remaining = rate_limit.raw_data['core']['remaining']
                reset = rate_limit.raw_data['core']['reset']
                if remaining <= 5:
                    timestamp = time.time()
                    wait_second = int(reset - timestamp)
                    if wait_second <= 0:
                        continue
                    print('wait ', wait_second)
                    time.sleep(wait_second + 2)
            except:
                print('abnormal no limit')
                time.sleep(60)
            trees_main = repo.get_git_tree(sha)
            store_result, _ = parse_file_names(trees_main, repo)

            store_dict[cve_and_repo] = (sha, store_result)
        except (Exception, KeyboardInterrupt) as e:
            if hasattr(e, 'status') and e.status == 403:
                time.sleep(2)
            print(e)
            del store_dict[cve_and_repo]
            save_text('tmp/second/error/info', f'{idx}: {token}')
            save_pickle(tmp_file, store_dict)
            break
    
    file_name = 'tmp/second/output/{(cve, repo_full_name): (sha: [file_list]}}' + f'_{idx}.pkl'
    save_pickle(file_name, store_dict)
    return store_dict


def get_repo_files(idx: int, token: str):
    cve_and_commit = load_pickle(f'tmp/second/input/block_{idx + 1}.pkl')

    store = {}
    cve_and_file_list = get_file_name(cve_and_commit, idx, token)
    g = Github(token)

    filter_list = [
        'changelog', 'news', 'changes', 'version','readme', 'license', 'authors', 'todo', 'history', 'copying', 'relnotes', 'thanks', 'notice','whatsnew', 'notes', 'release_notes', 'note', 'testlist', 'testsuite', 'test', '.gitignore', '.md', '.txt', '.docx', '.pdf', '.rst', '.changes', '.rdoc', '.mdown', '.command', '.out', '.err', '.stderr', '.stdout', '.test', '.jpg', '.png', '.svg', '.mp4', '.gif', '.exr', '.csv', '.rdf', '.ico', '.ttf', '.otf', '.woff', '.woff2', '.mock', '.stub', '.fake', '.pptx', '.key', '.bak', '.zip', '.gz', '.rar'
    ]

    tmp_file = f'tmp/second/mid/file_content_{idx}.pkl'
    if os.path.exists(tmp_file):
        store = load_pickle(tmp_file)
        # print(len(store))
        # print(store.keys())

    for cve_and_repo, sha_and_file_list in tqdm.tqdm(cve_and_file_list.items()):
        if store.get(cve_and_repo):
            continue
        store[cve_and_repo] = {}
        repo_full_name = cve_and_repo[1]
        sha = sha_and_file_list[0]
        file_list = sha_and_file_list[1]
        for file_path in file_list:
            tp = file_path.split('/')[-1]
            if any(element in tp for element in filter_list):
                # print('skip ', file_path)
                continue
            try:
                try:
                    rate_limit = g.get_rate_limit()
                    remaining = rate_limit.raw_data['core']['remaining']
                    reset = rate_limit.raw_data['core']['reset']
                    if remaining <= 5:
                        timestamp = time.time()
                        wait_second = int(reset - timestamp)
                        if wait_second <= 0:
                            continue
                        print('wait ', wait_second)
                        time.sleep(wait_second + 2)
                except:
                    print('abnormal no limit')
                    time.sleep(60)

                target_repo = g.get_repo(full_name_or_id = repo_full_name)

                try:
                    rate_limit = g.get_rate_limit()
                    remaining = rate_limit.raw_data['core']['remaining']
                    reset = rate_limit.raw_data['core']['reset']
                    if remaining <= 5:
                        timestamp = time.time()
                        wait_second = int(reset - timestamp)
                        if wait_second <= 0:
                            continue
                        print('wait ', wait_second)
                        time.sleep(wait_second + 2)
                except:
                    print('abnormal no limit')
                    time.sleep(60)

                content = target_repo.get_contents(path = file_path, ref = sha)
                store[cve_and_repo][file_path] = content
            except (Exception, KeyboardInterrupt) as e:
                if hasattr(e, 'status') and e.status == 403:
                    time.sleep(2)
                print(e)
                del store[cve_and_repo]
                save_text('tmp/second/error/info', f'{idx}: {token}')
                save_pickle(tmp_file, store)
                break

    target_path = 'tmp/second/output/{(cve, repo_full_name): {file_path: file_content}}' + f'_{idx}'
    save_pickle(f'{target_path}.pkl', store)
    
    return store


def split_data(block_num: int, data_path: str):
    cve_and_commit = load_pickle(data_path)
    total = len(cve_and_commit)
    block_size = int(total / block_num)

    tp = {}
    for idx, (k, v) in enumerate(cve_and_commit.items()):
        if idx and idx / block_size < block_num and idx % block_size == 0:
            file_name = f'tmp/second/input/block_{int(idx / block_size)}'
            save_text(file_name, tp)
            save_pickle(f'{file_name}.pkl', tp)
            tp = {}
        tp[k] = v
        if idx == total - 1:
            file_name = f'tmp/second/input/block_{int(idx / block_size)}'
            save_text(file_name, tp)
            save_pickle(f'{file_name}.pkl', tp)


if __name__ == '__main__':
    tokens = [
        
    ]
    block_num = len(tokens)
    split_data(block_num, 'tmp/input_2.pkl')

    threads = []
    for idx in range(block_num):
        thread = threading.Thread(target = get_repo_files, args = (idx, tokens[idx]))
        threads.append(thread)
    
    for thread in threads:
        thread.start()

    for thread in threads:
        thread.join()