import os

import tqdm
import torch
import tiktoken
import numpy as np
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
from transformers import AutoModelForSequenceClassification, AutoTokenizer

from util.io_util import load_pickle, save_pickle, save_text


max_token = 8192
model = 'text-embedding-3-small'
model_simple = model.split('/')[-1]

root_dir = '/Volumes/NVD/experiment_data/267'
repo_dir = f'{root_dir}/target'
text_dir = f'{root_dir}/text_{model_simple}'
descriptions_dir = f'{root_dir}/descriptions'
similarity_dir = f'{root_dir}/similarity_{model_simple}'
result_path = f'{root_dir}/result_{model_simple}'

filter_list = [
    'changelog', 'news', 'changes', 'changelog', 'version', 'readme', 'makefile', 'license', 'authors', 'todo', 'TODO', 'history', 'copying', 'relnotes', 'thanks', 'notice','whatsnew', 'notes', 'release_notes', 'note', 'testlist', 'testsuite', 'test', '.gitignore', '.xlsx', '.xls', '.md', '.txt', '.doc', '.docx', '.pdf', '.rst', '.changes', '.rdoc', '.mdown', '.command', '.out', '.err', '.stderr', '.stdout', '.test', '.jpg', '.jpeg', '.png', '.svg', '.mp4', '.gif', '.exr', '.csv', '.rdf', '.ico', '.ttf', '.otf', '.woff', '.woff2', '.mock', '.stub', '.fake', '.ppt', '.pptx', '.key', '.bak', '.zip', '.gz', '.rar', '.bmp', '.yaml', '.yml', '.json', '.xml', '.ini', '.cfg', '.tar.gz', '.tgz', '.html', '.htm', '.css', '.cygport', 'logo.', 'ui.js', 
]

filter_list_suffix = [
    '.lib'
]

reserve_list = ['mdcheck', 'lynis', 'chatsecure', 'rsync', 'gnome-exe-thumbnailer', 'public', 'source', 'makefile', 'openshift-port-proxy-cfg', 'bs_srcserver', 'dockerfile', 'rakefile', 'pyxtrlock', 'make-ca', 'fixfiles', 'kconfig', 'poco', 'deps', 'template', 'git-big-picture', 'data_upload', 'config', 'post-update', 'cryptstatus', 'sandbox', 'refresh_patches', 'pulp-gen-nodes-certificate', 'freewvs', 'kctf-cluster', 'unoconv', 'tomb', 'apt_repository', 'google_oslogin_control', 'passenger-install-nginx-module']

reserve_list_suffix = ['.cmake', '.swf', '.zsh', '.spec', '.rb', '.coffee', '.bro', '.source', '.scrbl', '.in', '.chatsecure', '.am', '.sol', '.pl', '.kconfig', '.tmpl', '.ftl', '.jsp', '.rakefile', '.ctp', '.sgml', '.l', '.cs', '.phtml', '.properties', '.ci', '.google_oslogin_control', '.clj', '.rabl', '.jar', '.m', '.sql', '.bat', '.conf', '.pulp-gen-nodes-certificate', '.java', '.rl', '.rsync', '.unoconv', '.sh', '.ac', '.lua', '.passenger-install-nginx-module', '.vue', '.gypi', '.mdcheck', '.r', '.haml', '.y', '.lynis', '.pm', '.pp', '.cfg', '.yml', '.mjs', '.make-ca', '.jsx', '.gitattributes', '.erl', '.inc', '.cc', '.rs', '.deps', '.wxs', '.cshtml', '.m4', '.patch', '.builder', '.cgi', '.ts', '.scm', '.script', '.nse', '.h', '.erb', '.sandbox', '.ejs', '.xs', '.tsx', '.phps', '.groovy', '.xst', '.makefile', '.gradle', '.dtml', '.mod', '.hpp', '.yaml', '.cxx', '.tpl', '.openshift-port-proxy-cfg', '.tomb', '.htm', '.fixfiles', '.lock', '.html', '.ini', '.hh', '.data_upload', '.cpp', '.mustache', '.fish', '.bs_srcserver', '.ps1', '.cryptstatus', '.xml', '.blacklist', '.freewvs', '.vm', '.py', '.refresh_patches', '.json', '.gemspec', '.release', '.d-mongod', '.re', '.rsb', '.git-big-picture', '.nim', '.go', '.config', '.vala', '.ex', '.factories', '.swift', '.ti', '.poco', '.public', '.s', '.scala', '.dockerfile', '.apt_repository', '.twig', '.resolved', '.as', '.toml', '.template', '.dist', '.jelly', '.pyx', '.gnome-exe-thumbnailer', '.htaccess', '.kt', '.nix', '.kctf-cluster', '.pyxtrlock', '.js', '.ls', '.php', '.c', '.hbs', '.c++', '.post-update']



if model == 'text-embedding-3-small':
    load_dotenv()
    client = OpenAI()
elif model in ['BAAI/bge-reranker-v2-m3']:
    device = torch.device("cuda")
    tokenizer = AutoTokenizer.from_pretrained(model)
    model = AutoModelForSequenceClassification.from_pretrained(model)
    model.to(device)
    model.eval()


def calc_token(text):
    if model == 'text-embedding-3-small':
        enc = tiktoken.get_encoding("cl100k_base")
        enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
        return len(enc.encode(text))
    elif model == 'BAAI/bge-reranker-v2-m3':
        return len(tokenizer.encode(text))
    return 0


def get_embedding(text):
    text = text.replace("\n", " ")
    if model == 'text-embedding-3-small':
        return client.embeddings.create(input = [text], model = model).data[0].embedding
    elif model == 'BAAI/bge-reranker-v2-m3':
        pass


def split_file_content(cve: str):
    output_file = f'{text_dir}/{cve}.csv'
    if os.path.exists(output_file):
        return pd.read_csv(output_file)
    
    with open(f'{descriptions_dir}/{cve}') as f:
        description = f.read()
    df = pd.DataFrame({
        'repo_name': ['null'],
        'file_name': ['null'],
        'text': [description]
    })

    path = f'{repo_dir}/{cve}'
    repos = os.listdir(path)
    for repo in repos:
        repo_name = repo.replace('—', '/')
        rec(df, repo_name, f'{path}/{repo}')
    df.to_csv(f'{text_dir}/{cve}.csv', index = False)
    return df


def rec(df, repo_name: str, full_path: str):
    file_name = full_path.split('/')[-1].lower()
    if os.path.isdir(full_path):
        for item in os.listdir(full_path):
            rec(df, repo_name, f'{full_path}/{item}')
    elif 'test' in full_path or 'note' in full_path or 'license' in full_path or any(element in file_name for element in filter_list) or any(file_name.endswith(suffix) for suffix in filter_list_suffix):
        pass
    elif any(file_name.endswith(suffix) for suffix in reserve_list_suffix) or file_name in reserve_list:
        try:
            with open(full_path, 'r') as f:
                content = f.read()
        except UnicodeDecodeError:      # 非文本文件
            return
        token_len = calc_token(content)
        if token_len > max_token:
            content_len = len(content)
            block_count = int(token_len / max_token) + 1
            block_size = int(content_len / block_count)
            cur = 0
            while cur + block_size < content_len:
                if content[cur : cur + block_size]:
                    df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[7:]), content[cur : cur + block_size]]
                cur += block_size                
            else:
                if cur < content_len:
                    df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[7:]), content[cur:]]
        elif content:
            df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[7:]), content]

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def calc_similarity(cve, df):
    output_file = f'{similarity_dir}/{cve}.csv'
    if os.path.exists(output_file):
        return pd.read_csv(output_file)

    if model == 'text-embedding-3-small':
        df['vector'] = df.text.apply(lambda x: get_embedding(x))
        description_vector = df.loc[0].vector
        df['similarity'] = df.vector.apply(lambda x: cosine_similarity(x, description_vector))
    elif model == 'BAAI/bge-reranker-v2-m3':
        desc = df.loc[0].text
        similarity = []
        with torch.no_grad():
            for text in df.text:
                inputs = tokenizer([[text, desc]], padding=True, truncation=True, return_tensors='pt', max_length=max_token).to('cuda')
                scores = model(**inputs, return_dict=True).logits.view(-1, ).float()
                similarity.append(scores.cpu().numpy())
        df['similarity'] = similarity

    df = df.sort_values('similarity', ascending = False)
    df.to_csv(f'{similarity_dir}/{cve}.csv', index = False)
    return df


def select_file_candidates(k: int, ground_truth: dict):
    # cve_list = load_pickle('/Volumes/NVD/experiment_data/267/procedure_data/cve_list_205.pkl')
    cve_list = [
        'CVE-2018-1000888', 'CVE-2015-8748', 'CVE-2019-11411', 'CVE-2019-11412', 'CVE-2017-15010', 'CVE-2021-28363', 'CVE-2020-26137', 'CVE-2019-20479', 'CVE-2022-23614', 'CVE-2019-1010305', 'CVE-2020-8203', 'CVE-2022-24724', 'CVE-2013-7436', 'CVE-2020-9274', 'CVE-2019-15026', 'CVE-2022-29869', 'CVE-2020-4067', 'CVE-2019-16235', 'CVE-2019-16236', 'CVE-2019-16237', 'CVE-2020-14399', 'CVE-2020-14400', 'CVE-2020-14401', 'CVE-2019-19204', 'CVE-2019-1010319', 'CVE-2019-1010317', 'CVE-2020-27783', 'CVE-2018-1002200', 'CVE-2022-30784', 'CVE-2018-15127', 'CVE-2018-20019'
    ]
    rank = {}
    candidate_file_list = {}
    for cve in tqdm.tqdm(cve_list):
        df = split_file_content(cve)
        df = calc_similarity(cve, df)
        df.drop(df.index[0], inplace = True)

        rank[cve] = -1
        candidate_file_list[cve] = []
        for index, (_, row) in enumerate(df.iterrows()):
            if len(candidate_file_list[cve]) < k and (row.repo_name, row.file_name) not in candidate_file_list[cve]:
                candidate_file_list[cve].append((row.repo_name, row.file_name))
            if rank[cve] == -1 and row.file_name.lower() == ground_truth[cve].lower():
                rank[cve] = index
            if rank[cve] != -1 and len(candidate_file_list[cve]) >= k:
                break
    
    save_text(result_path, rank)
    # save_pickle(f'{result_path}.pkl', rank)
    # return candidate_file_list


if __name__ == '__main__':
    ground_truth = {
        'CVE-2018-1000888': 'archive/tar.php',
        'CVE-2015-8748': 'radicale/rights/regex.py',
        'CVE-2019-11411': 'jsnumber.c',
        'CVE-2019-11412': 'jscompile.c',
        'CVE-2017-15010': 'lib/cookie.js', 
        'CVE-2021-28363': 'src/urllib3/connection.py',
        'CVE-2020-26137': 'src/urllib3/connection.py',
        'CVE-2019-20479': 'src/mod_auth_openidc.c',
        'CVE-2022-23614': 'src/extension/coreextension.php',
        'CVE-2019-1010305': 'libmspack/mspack/chmd.c',
        'CVE-2020-8203': 'lodash.js',
        'CVE-2022-24724': 'extensions/table.c',
        'CVE-2013-7436': 'include/webutil.js',
        'CVE-2020-9274': 'src/diraliases.c',
        'CVE-2019-15026': 'memcached.c',
        'CVE-2022-29869': 'mount.cifs.c',
        'CVE-2020-4067': 'src/apps/relay/ns_ioalib_engine_impl.c',
        'CVE-2019-16235': 'xmpp-vala/src/module/xep/0280_message_carbons.vala',
        'CVE-2019-16236': 'xmpp-vala/src/module/roster/module.vala',
        'CVE-2019-16237': 'xmpp-vala/src/module/xep/0313_message_archive_management.vala',
        'CVE-2020-14399': 'libvncclient/rfbproto.c',
        'CVE-2020-14400': 'libvncserver/translate.c',
        'CVE-2020-14401': 'libvncserver/scale.c',
        'CVE-2019-19204': 'src/regparse.c',
        'CVE-2019-1010319': 'cli/wave64.c',
        'CVE-2019-1010317': 'cli/caff.c',
        'CVE-2020-27783': 'src/lxml/html/clean.py',
        'CVE-2018-1002200': 'src/main/java/org/codehaus/plexus/archiver/abstractunarchiver.java',
        'CVE-2022-30784': 'libntfs-3g/attrib.c',
        'CVE-2018-15127': 'libvncserver/rfbserver.c',
        'CVE-2018-20019':'libvncclient/rfbproto.c'
    }
    select_file_candidates(10, ground_truth)