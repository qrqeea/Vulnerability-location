import os
import tiktoken
import tqdm
import pandas as pd
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv
from util import load_pickle


filter_list = [
    'changelog', 'news', 'changes', 'ChangeLog', 'version', 'readme', 'README', 'makefile', 'Makefile', 'license', 'authors', 'todo', 'TODO', 'history', 'copying', 'relnotes', 'thanks', 'notice','whatsnew', 'notes', 'release_notes', 'note', 'testlist', 'testsuite', 'test', '.gitignore', '.md', '.txt', '.docx', '.pdf', '.rst', '.changes', '.rdoc', '.mdown', '.command', '.out', '.err', '.stderr', '.stdout', '.test', '.jpg', '.png', '.svg', '.mp4', '.gif', '.exr', '.csv', '.rdf', '.ico', '.ttf', '.otf', '.woff', '.woff2', '.mock', '.stub', '.fake', '.pptx', '.key', '.bak', '.zip', '.gz', '.rar'
]

load_dotenv()
client = OpenAI()

def calctoken(input):
    enc = tiktoken.get_encoding("cl100k_base")
    enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
    return len(enc.encode(input))


def get_embedding(text, model="text-embedding-3-small"):
   text = text.replace("\n", " ")
   return client.embeddings.create(input = [text], model=model).data[0].embedding


def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def rec(df, repo_name: str, full_path: str):
    file_name = full_path.split('/')[-1]
    if os.path.isdir(full_path):
        for item in os.listdir(full_path):
            rec(df, repo_name, f'{full_path}/{item}')
    elif any(element in file_name for element in filter_list):
        pass
    else:
        try:
            with open(full_path, 'r') as f:
                content = f.read()
        except UnicodeDecodeError:      # 非文本文件
            return
        token_len = calctoken(content)
        if token_len > 8000:
            block = int(token_len / 8192) + 1
            for i in range(block):
                l = i * 8192
                r = min(len(content), (i + 1) * 8192)
                if content[l:r]:
                    df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[5:]), content[l:r]]
        elif content:
            df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[5:]), content]


def split_file_content(cve: str):
    with open(f'experiment_data/267/descriptions/{cve}') as f:
        description = f.read()
    df = pd.DataFrame(
        {
            'repo_name': ['null'],
            'file_name': ['null'],
            'content': [description]
        }
    )
    path = f'experiment_data/267/target/{cve}'
    repos = os.listdir(path)
    for repo in tqdm.tqdm(repos):
        repo_name = repo.replace('—', '/')
        rec(df, repo_name, f'{path}/{repo}')
    df.to_csv(f'experiment_data/267/vector/{cve}.csv', index = False)
    return df


def text_to_vector(cve_list: list):
    for cve in tqdm.tqdm(cve_list):
        df = split_file_content(cve)
    
        df['vector'] = df.content.apply(lambda x: get_embedding(x))
        description_vector = df.loc[0].vector
        df['similarities'] = df.vector.apply(lambda x: cosine_similarity(x, description_vector))
        df = df.sort_values('similarities', ascending = False)
        df.to_csv(f'experiment_data/267/similarities/{cve}.csv', index = False)
        print(df.head(20))


# def select_file_candidates(k: int):
#     cve_list = load_pickle('experiment_data/267valid_cve_list.pkl')
#     text_to_vector(cve_list)



if __name__ == '__main__':
    # df = split_file_content('CVE-2019-1010305')
    # print(df)

    # cve_list = load_pickle('experiment_data/267valid_cve_list.pkl')[:20]
    text_to_vector(['CVE-2019-1010305'])