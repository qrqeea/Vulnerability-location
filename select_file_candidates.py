import os

import tqdm
import tiktoken
import numpy as np
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv

from util import load_pickle, save_pickle, save_text


filter_list = [
    'changelog', 'news', 'changes', 'changelog', 'version', 'readme', 'makefile', 'license', 'authors', 'todo', 'TODO', 'history', 'copying', 'relnotes', 'thanks', 'notice','whatsnew', 'notes', 'release_notes', 'note', 'testlist', 'testsuite', 'test', '.gitignore', '.xlsx', '.xls', '.md', '.txt', '.doc', '.docx', '.pdf', '.rst', '.changes', '.rdoc', '.mdown', '.command', '.out', '.err', '.stderr', '.stdout', '.test', '.jpg', '.jpeg', '.png', '.svg', '.mp4', '.gif', '.exr', '.csv', '.rdf', '.ico', '.ttf', '.otf', '.woff', '.woff2', '.mock', '.stub', '.fake', '.ppt', '.pptx', '.key', '.bak', '.zip', '.gz', '.rar', '.bmp', '.yaml', '.yml', '.json', '.xml', '.ini', '.cfg', '.tar.gz', '.tgz', '.html', '.htm', '.css', '.cygport'
]

load_dotenv()
client = OpenAI()

def calctoken(input):
    enc = tiktoken.get_encoding("cl100k_base")
    enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
    return len(enc.encode(input))


def get_embedding(text, model = "text-embedding-3-small"):
   text = text.replace("\n", " ")
   return client.embeddings.create(input = [text], model=model).data[0].embedding


def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def rec(df, repo_name: str, full_path: str):
    file_name = full_path.split('/')[-1].lower()
    if os.path.isdir(full_path):
        for item in os.listdir(full_path):
            rec(df, repo_name, f'{full_path}/{item}')
    elif '.' not in file_name or 'test' in full_path or 'note' in full_path or 'license' in full_path or any(element in file_name for element in filter_list):
        pass
    else:
        try:
            with open(full_path, 'r') as f:
                content = f.read()
        except UnicodeDecodeError:      # 非文本文件
            return
        token_len = calctoken(content)
        if token_len > 8000:
            block = int(token_len / 8192) + 1
            for i in range(block):
                l = i * 8192
                r = min(len(content), (i + 1) * 8192)
                if content[l:r]:
                    df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[8:]), content[l:r]]
        elif content:
            df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[8:]), content]


def split_file_content(cve: str):
    with open(f'/Volumes/Data/experiment_data/267/descriptions/{cve}') as f:
        description = f.read()
    df = pd.DataFrame(
        {
            'repo_name': ['null'],
            'file_name': ['null'],
            'content': [description]
        }
    )
    path = f'/Volumes/Data/experiment_data/267/target/{cve}'
    repos = os.listdir(path)
    for repo in tqdm.tqdm(repos):
        repo_name = repo.replace('—', '/')
        rec(df, repo_name, f'{path}/{repo}')
    df.to_csv(f'/Volumes/Data/experiment_data/267/vector/{cve}.csv', index = False)
    return df


def text_to_vector(cve: str):
    df = split_file_content(cve)

    df['vector'] = df.content.apply(lambda x: get_embedding(x))
    description_vector = df.loc[0].vector
    df['similarities'] = df.vector.apply(lambda x: cosine_similarity(x, description_vector))
    df = df.sort_values('similarities', ascending = False)
    df.to_csv(f'/Volumes/Data/experiment_data/267/similarities/{cve}.csv', index = False)
    return df


def select_file_candidates(k: int):
    cve_list = load_pickle('/Volumes/Data/experiment_data/267/procedure_data/cve_list_205.pkl')
    cve_list = ['CVE-2018-1000888', 'CVE-2018-1002200']
    # 'CVE-2019-14751'
    res = {}
    for cve in tqdm.tqdm(cve_list):
        df = text_to_vector(cve)
        df.drop(df.index[0], inplace = True)
        
        res[cve] = set()
        for _, row in df.iterrows():
            res[cve].add((row.repo_name, row.file_name))
            if len(res[cve]) > k:
                break
    save_pickle('/Volumes/Data/experiment_data/267/result.pkl', res)
    save_text('/Volumes/Data/experiment_data/267/result', res)
    return res


if __name__ == '__main__':
    select_file_candidates(10)