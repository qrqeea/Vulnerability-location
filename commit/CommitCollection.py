import tqdm
import random
from util.io_util import *
from util.github_util import *


class CommitCollection:

    def __init__(self, project_root_path: str, module_root_path: str, repo_data_path: str, cve_data_all: dict):
        self.project_root_path = project_root_path
        self.module_root_path = module_root_path
        self.repo_data_path = repo_data_path
        self.cve_data_all = cve_data_all

        os.makedirs(self.module_root_path, exist_ok = True)
        os.makedirs(self.repo_data_path, exist_ok = True)

        # 这个模块的target cve list是上一步收集到repo的cve
        self.cve_list = [k for k, v in self.cve_data_all.items() if 'collected_repo' in v]
        print(f'cve count: {len(self.cve_list)}')   # 8427

        repo_all = set()
        for _, v in self.cve_data_all.items():
            if 'collected_repo' in v:
                repo_all |= set(v['collected_repo'])
        self.repo_all = repo_all
        print(f'repo count: {len(self.repo_all)}')  # 2514


    def start(self):
        repo_all_branch = self.get_repo_all_branch()
        data = self.get_latest_commit_before_date_all(repo_all_branch)
        repo_latest_sha_before_date = self.convert_data(data)
        self.select_commit(repo_latest_sha_before_date)
        self.get_specified_file_list()
        self.check_commit_accuracy()


    def get_repo_all_branch(self):
        path = f'{self.repo_data_path}/repo_all_branch'
        if os.path.exists(f'{path}.pkl'):
            return load_pickle(f'{path}.pkl')

        def get_repo_all_branch_sub(repo_list_sub: list, token: str):
            for repo in tqdm.tqdm(repo_list_sub):
                all_branch = get_all_branch(repo, token)
                repo_all_branch[repo] = all_branch

        print('start search repo\'s all branch')

        repo_all_branch = load_pickle(f'{path}.pkl') if os.path.exists(f'{path}.pkl') else {}
        
        rest_repo = list(set(self.repo_all) - set(repo_all_branch.keys()))
        print(f'rest repo count: {len(rest_repo)}')
        
        multi_thread(rest_repo, get_repo_all_branch_sub, tokens = github_tokens)

        save_json(f'{path}.json', repo_all_branch)
        save_pickle(f'{path}.pkl', repo_all_branch)

        print('end search repo\'s all branch\n')
        return repo_all_branch        


    def get_latest_commit_before_date_all(self, repo_all_branch: dict):
        # 以repo为key，搜索所有分支在某个日期前的最新commit
        path = f'{self.repo_data_path}/repo_latest_sha_before_date(set)'
        if os.path.exists(f'{path}.pkl'):
            return load_pickle(f'{path}.pkl')

        if not any('adjusted_date' in v for v in self.cve_data_all.values()):
            for cve in self.cve_list:
                published_date = self.cve_data_all[cve]['published_date']
                year1 = int(published_date[:4])
                year2 = int(cve[4:8])
                if abs(year1 - year2) > 1:
                    self.cve_data_all[cve]['adjusted_date'] = f'{year2}-06-30T00:00Z'
                else:
                    self.cve_data_all[cve]['adjusted_date'] = published_date
            save_json(f'{self.project_root_path}/cve_data_all.json', self.cve_data_all)
            save_pickle(f'{self.project_root_path}/cve_data_all.pkl', self.cve_data_all)
        
        def get_latest_commit_before_date_all_sub(to_scrapy_list_sub: list, token: str):
            for repo, date, branch in tqdm.tqdm(to_scrapy_list_sub):
                commit_sha = get_latest_commit_before_date(repo, date, token, branch)
                if commit_sha:
                    repo_latest_sha_before_date[repo][date].add(commit_sha)

        print('start search repo\'s latest_commit_before_date')
        
        repo_latest_sha_before_date = load_pickle(f'{path}.pkl') if os.path.exists(f'{path}.pkl') else {}
        to_scrapy_list = set()
        for cve in self.cve_list:
            dates = {self.cve_data_all[cve]['adjusted_date'], self.cve_data_all[cve]['published_date']}
            for date in dates:
                for repo in self.cve_data_all[cve]['collected_repo']:
                    if repo not in repo_latest_sha_before_date:
                        repo_latest_sha_before_date[repo] = {}
                    if date not in repo_latest_sha_before_date[repo]:
                        repo_latest_sha_before_date[repo][date] = set()
                    if repo_latest_sha_before_date[repo][date]: continue
                    for branch in repo_all_branch[repo]:
                        to_scrapy_list.add((repo, date, branch))
        save_text(f'{self.module_root_path}/to_scrapy_list', to_scrapy_list)
        save_pickle(f'{self.module_root_path}/to_scrapy_list.pkl', to_scrapy_list)
        
        print(f'to_scrapy_list size: {len(to_scrapy_list)}')
        # multi_thread(random.sample(list(to_scrapy_list), 10), get_latest_commit_before_date_all_sub, tokens = github_tokens)
        multi_thread(list(to_scrapy_list), get_latest_commit_before_date_all_sub, tokens = github_tokens)
        
        save_pickle(f'{path}.pkl', repo_latest_sha_before_date)
    
        print('end search repo\'s latest_commit_before_date')
        return repo_latest_sha_before_date


    def convert_data(self, data: dict):
        path = f'{self.repo_data_path}/repo_latest_sha_before_date'
        if os.path.exists(f'{path}.pkl'):
            return load_pickle(f'{path}.pkl')

        repo_latest_sha_before_date = {}
        for repo, v in data.items():
            if repo not in repo_latest_sha_before_date:
                repo_latest_sha_before_date[repo] = {}
            for date, shas in v.items():
                if shas:
                    repo_latest_sha_before_date[repo][date] = sorted(list(shas), key = lambda x: x[1], reverse = True)
            if not repo_latest_sha_before_date[repo]:
                del repo_latest_sha_before_date[repo]
        save_json(f'{path}.json', repo_latest_sha_before_date)
        save_pickle(f'{path}.pkl', repo_latest_sha_before_date)
        
        return repo_latest_sha_before_date


    def select_commit(self, data: dict):
        path = f'{self.module_root_path}/collected_commits'
        if os.path.exists(f'{path}.json'):
            return
        
        collected_commits = {}
        for cve in tqdm.tqdm(self.cve_list):
            adjusted_date = self.cve_data_all[cve]['adjusted_date']
            published_date = self.cve_data_all[cve]['published_date']
            for repo in self.cve_data_all[cve]['collected_repo']:
                if repo not in data: continue
                if adjusted_date in data[repo] and data[repo][adjusted_date]:
                    if cve not in collected_commits:
                        collected_commits[cve] = []
                    collected_commits[cve].append((repo, data[repo][adjusted_date][0][0]))
                    continue
                if published_date in data[repo] and data[repo][published_date]:
                    if cve not in collected_commits:
                        collected_commits[cve] = []
                    collected_commits[cve].append((repo, data[repo][published_date][0][0]))
        save_json(f'{path}.json', collected_commits)
        save_pickle(f'{path}.pkl', collected_commits)

        for cve, commits in collected_commits.items():
            self.cve_data_all[cve]['collected_commit'] = commits
        
        save_json(f'{self.project_root_path}/cve_data_all.json', self.cve_data_all)
        save_pickle(f'{self.project_root_path}/cve_data_all.pkl', self.cve_data_all)
    

    def get_specified_file_list(self):
        path = f'{self.repo_data_path}/repo_file_list'
        if os.path.exists(f'{path}.pkl'):
            return load_pickle(f'{path}.pkl')

        def get_specified_file_list_sub(cve_list_sub: list, token: str):
            for (repo, sha) in tqdm.tqdm(cve_list_sub):
                if repo not in repo_file_list:
                    repo_file_list[repo] = {}
                if sha not in repo_file_list[repo]:
                    repo_file_list[repo][sha] = get_file_list(repo, sha, token)

        data = load_pickle(f'{self.module_root_path}/collected_commits.pkl')
        repo_file_list = load_pickle(f'{path}.pkl') if os.path.exists(f'{path}.pkl') else {}

        data_list = list({
            (repo, sha)
            for v in data.values()
            for (repo, sha) in v
            if not (repo in repo_file_list and sha in repo_file_list[repo])
        })
        print(len(data_list))
        multi_thread(data_list, get_specified_file_list_sub, tokens = github_tokens)

        save_json(f'{path}.json', repo_file_list)
        save_pickle(f'{path}.pkl', repo_file_list)


    def check_commit_accuracy(self):
        count = 0
        total_count = 0
        correct_cve_list = set()
        repo_file_list = load_pickle(f'{self.repo_data_path}/repo_file_list.pkl')

        for cve in tqdm.tqdm(self.cve_list):

            collected_commit = self.cve_data_all[cve].get('collected_commit')
            if not collected_commit: continue
            total_count += 1

            flag = False
            file_ans_list = self.cve_data_all[cve]['file_list']
            for repo, sha in collected_commit:
                if flag:
                    break

                file_list = repo_file_list[repo][sha]
                for file, _ in file_list:
                    # if file in file_ans_list:
                    # if any(file_ans.lower() in file.lower() for file_ans in file_ans_list):
                    if any(file.lower() in file_ans.lower() for file_ans in file_ans_list):
                    # if any((file_ans.lower() in file.lower() or file.lower() in file_ans.lower()) for file_ans in file_ans_list):
                        # print(cve)
                        correct_cve_list.add(cve)
                        flag = True
                        count += 1
                        break
        #     if flag:
        #         count += 1
        #         self.cve_data_all[cve]['collected_commit_correction'] = True
        #     else:
        #         self.cve_data_all[cve]['collected_commit_correction'] = False
        
        # save_json(f'{self.project_root_path}/cve_data_all.json', self.cve_data_all)
        # save_pickle(f'{self.project_root_path}/cve_data_all.pkl', self.cve_data_all)

        # save_text(f'{self.module_root_path}/correct_commit_cve_list', correct_cve_list)
        print(f'accuracy: {count/total_count}, {count}/{total_count}')