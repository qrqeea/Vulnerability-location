import tqdm
import random
from util.io_util import *
from util.github_util import *


class CommitCollection:

    def __init__(self, project_root_path: str, module_root_path: str, cve_data_all: dict):
        self.project_root_path = project_root_path
        self.module_root_path = module_root_path
        self.cve_data_all = cve_data_all

        os.makedirs(self.module_root_path, exist_ok = True)

        # 这个模块的target cve list是上一步收集到repo的cve（之后会删减）
        self.cve_list = [k for k, v in self.cve_data_all.items() if 'collected_repo' in v]
        # print(len(self.cve_list))     # 7587

        self.repo_all_branch = self.get_repo_all_branch()


    def start(self):
        self.get_commit()
        self.get_specified_file_list()
        self.check_commit_accuracy()
        

    def get_commit(self):

        def get_commit_sub(cve_list_sub: list, token: str):
            for cve in tqdm.tqdm(cve_list_sub):
                res[cve] = []
                for repo in self.cve_data_all[cve]['collected_repo']:
                    flag = False
                    for branch in self.repo_all_branch[repo]:
                        commit_sha = get_latest_commit_before_date(repo, self.cve_data_all[cve]['published_date'], token, branch)
                        if commit_sha:
                            res[cve].append((repo, commit_sha))
                            flag = True
                            break
                    if not flag:
                        not_found_tuple.append((cve, repo))
                if not res[cve]:
                    del res[cve]
                    # print('del', cve)

        print(f'start search commit, cve size: {len(self.cve_list)}')

        res = {}
        not_found_tuple = []
        # multi_thread(random.sample(self.cve_list, 2), get_commit_sub, tokens = github_tokens)
        multi_thread(self.cve_list, get_commit_sub, tokens = github_tokens)
        
        print(f'end search commit, {len(res)} cve found commit, {len(self.cve_list) - len(res)} cve not found')
        
        save_json(f'{self.module_root_path}/collected_commits.json', res)
        save_pickle(f'{self.module_root_path}/collected_commits.pkl', res)

        save_text(f'{self.module_root_path}/not_found_tuple', not_found_tuple)

        for cve, v in res.items():
            self.cve_data_all[cve]['collected_commit'] = v
        
        save_json(f'{self.project_root_path}/cve_data_all.json', self.cve_data_all)
        save_pickle(f'{self.project_root_path}/cve_data_all.pkl', self.cve_data_all)


    def get_specified_file_list(self):
        def get_specified_file_list_sub(cve_list_sub: list, token: str):
            for (repo, sha) in tqdm.tqdm(cve_list_sub):
                if repo not in repo_file_list_table:
                    repo_file_list_table[repo] = {}
                if sha not in repo_file_list_table[repo]:
                    repo_file_list_table[repo][sha] = get_file_list(repo, sha, token)


        data = load_pickle(f'{self.module_root_path}/collected_commits.pkl')
        if os.path.exists(f'{self.module_root_path}/repo_file_list_table.pkl'):
            repo_file_list_table = load_pickle(f'{self.module_root_path}/repo_file_list_table.pkl')
        else:
            repo_file_list_table = {}

        data_list = list({
            (repo, sha)
            for v in data.values()
            for (repo, sha) in v
        })
        print(len(data_list))
        multi_thread(data_list, get_specified_file_list_sub, tokens = github_tokens)

        save_json(f'{self.module_root_path}/repo_file_list_table.json', repo_file_list_table)
        save_pickle(f'{self.module_root_path}/repo_file_list_table.pkl', repo_file_list_table)


    def check_commit_accuracy(self):
        count = 0
        total_count = 0
        correct_cve_list = set()
        repo_file_list_table = load_pickle(f'{self.module_root_path}/repo_file_list_table.pkl')

        for cve in tqdm.tqdm(self.cve_list):
            collected_commit = self.cve_data_all[cve].get('collected_commit')
            if not collected_commit: continue
            total_count += 1

            flag = False
            file_ans_list = self.cve_data_all[cve]['files']
            for repo, sha in collected_commit:
                if flag:
                    break

                file_list = repo_file_list_table[repo][sha]
                for file, _ in file_list:
                    # if any(file_ans in file for file_ans in file_ans_list):
                    #     flag = True
                    #     break
                    if any(file_ans.lower() in file.lower() for file_ans in file_ans_list):
                        # print(cve)
                        correct_cve_list.add(cve)
                        flag = True
                        break
            if flag:
                count += 1
                self.cve_data_all[cve]['collected_commit_correction'] = True
            else:
                self.cve_data_all[cve]['collected_commit_correction'] = False
        
        save_json(f'{self.project_root_path}/cve_data_all.json', self.cve_data_all)
        save_pickle(f'{self.project_root_path}/cve_data_all.pkl', self.cve_data_all)

        save_text(f'{self.module_root_path}/correct_commit_cve_list', correct_cve_list)
        print(f'accuracy: {count/total_count}, {count}/{total_count}')


    def get_repo_all_branch(self):
        if os.path.exists(f'{self.module_root_path}/repo_all_branch.pkl'):
            return load_pickle(f'{self.module_root_path}/repo_all_branch.pkl')

        def get_repo_all_branch_sub(repo_list_sub: list, token: str):
            for repo in tqdm.tqdm(repo_list_sub):
                all_branch = get_all_branch(repo, token)
                res[repo] = all_branch

        print('start search repo\'s all branch')
        repo_all = set()
        for _, v in self.cve_data_all.items():
            if 'collected_repo' in v:
                repo_all |= set(v['collected_repo'])
        print(len(repo_all))

        res = {}
        multi_thread(list(repo_all), get_repo_all_branch_sub, tokens = github_tokens)
        new_res = {}

        priority_branch_list = ['master', 'main', 'develop', 'dev', 'gh-pages']
        for repo, branchs in res.items():
            tp = ['']
            for branch in branchs:
                if branch in priority_branch_list:
                    tp.append(branch)
            for branch in branchs:
                if branch not in tp:
                    tp.append(branch)
            new_res[repo] = tp

        save_json(f'{self.module_root_path}/repo_all_branch.json', new_res)
        save_pickle(f'{self.module_root_path}/repo_all_branch.pkl', new_res)

        print('end search repo\'s all branch\n')
        return res