import os
import re
import tqdm
import shutil
from util.io_util import load_pickle, save_pickle, copy_file, save_json, load_json

'''
从NVD官网下载的json数据中提取需要的部分, 然后与ground_truth_data合并成一个dict
- reference_list: 
    type: [str]
- original_description:
    type: str
- published_date:
    type: str
- cpe_product:
    type: [str]
- cpe_uri:
    type: [str]
- repo_list:
    type: [str]
- file_list:
    type: [str]
- vulnerability_files:
    type: {repo: [files]}
'''


def get_product_from_cpe(s: str):
    s = s.replace('\:', '')
    pattern = r'(?<=:)([^:]+):([^:]+):([^:]+):([^:]+):([^:]+):'
    match = re.search(pattern, s)
    if match:
        return match.group(4)
    else:
        return None


def filter_json_file(cve_list: list, cve_json_path: str, target_path: str):
    file_list = []
    for root, _, files in os.walk(cve_json_path):
        for file in files:
            if file not in ['.DS_Store', 'delta.json', 'deltaLog.json']:
                file_list.append(os.path.join(root, file))

    for file in file_list:
        cve_id = file.split('/')[-1].split('.')[0]
        if cve_id not in cve_list:
            continue

        try:
            # data = load_json(file)
            # if data['cveMetadata']['state'] == 'REJECTED':
            #     print('REJECTED', cve_id)
            #     continue
            # if 'references' not in data['containers']['cna'].keys():
            #     print('no reference', cve_id)
            #     continue
            # references = data['containers']['cna']['references']
            copy_file(file, f'{target_path}/{cve_id}.json')
        except Exception as e:
            # print(e)
            print(f'error: open {cve_id}.json failure')


def preprocessing_data(ground_truth: dict, project_root_path: str, cve_json_path: str, cpe_json_path: str):

    if os.path.exists(f'{project_root_path}/cve_data_all.pkl'):
        return load_pickle(f'{project_root_path}/cve_data_all.pkl')
    
    temp_path = f'{project_root_path}/cve_json_{len(ground_truth)}'
    os.makedirs(temp_path, exist_ok = True)

    cve_list = {item for item in ground_truth.keys()}

    print('start traverse cve json file')
    filter_json_file(
        cve_list = cve_list,
        cve_json_path = cve_json_path,
        target_path = temp_path
    )
    print('end traverse cve json file')

    cve_data_all = {}
    for cve in cve_list:
        cve_data_all[cve] = {}
        filePath = f'{temp_path}/{cve}.json'
        data = load_json(filePath)
        cve_data_all[cve]['original_description'] = data['containers']['cna']['descriptions'][0]['value']
        cve_data_all[cve]['reference_list'] = [dic['url'] for dic in data['containers']['cna']['references']]

    print('start traverse cpe json file')
    for file in tqdm.tqdm(os.listdir(cpe_json_path)):
        if file in ['.DS_Store']: continue
        
        fileName = f'{cpe_json_path}/{file}'
        data = load_json(fileName)['CVE_Items']
        for cve_dic in data:
            cve = cve_dic['cve']['CVE_data_meta']['ID']
            if cve not in cve_list: continue

            cpe_uri_set = set()
            cpe_product_set = set()
            cpe_list = cve_dic['configurations']['nodes'][0]['cpe_match']
            if not cpe_list:
                cpe_list = cve_dic['configurations']['nodes'][0]['children'][0]['cpe_match']
            for cpe_dic in cpe_list:
                cpe_uri = cpe_dic['cpe23Uri']
                cpe_product_set.add(get_product_from_cpe(cpe_uri))
                cpe_uri_set.add(cpe_uri)
            cve_data_all[cve]['cpe_uri'] = list(cpe_uri_set)
            cve_data_all[cve]['cpe_product'] = list(cpe_product_set)

            time = cve_dic.get('publishedDate')
            cve_data_all[cve]['published_date'] = time

    print('end traverse cpe json file')

    for cve, v in ground_truth.items():        
        cve_data_all[cve]['repo_list'] = list(v['vulnerability_files'].keys())
        cve_data_all[cve]['file_list'] = list({ file
            for files in v['vulnerability_files'].values()
            for file in files
        })
        cve_data_all[cve]['vulnerability_files'] = v['vulnerability_files']

    cve_data_all = correct_data(cve_data_all)

    save_json(f'{project_root_path}/cve_data_all.json', cve_data_all)
    save_pickle(f'{project_root_path}/cve_data_all.pkl', cve_data_all)

    # shutil.rmtree(temp_path)
    
    return cve_data_all


def correct_data(cve_data_all: dict):
    # 手动修正一些数据
    # 重复数据
    url = 'https://talosintelligence.com/vulnerability_reports/TALOS-2021-1297'
    for cve in ['CVE-2021-21845', 'CVE-2021-21843', 'CVE-2021-21837', 'CVE-2021-21846', 'CVE-2021-21847', 'CVE-2021-21852', 'CVE-2021-21839', 'CVE-2021-21844', 'CVE-2021-21838']:
        cve_data_all[cve]['reference_list'].remove(url)

    return cve_data_all