import os
import json
import pickle
from urllib.parse import urlparse

def get_domain(url):
    parsed_url = urlparse(url)
    return parsed_url.netloc

totalcount = 0
urlCount = {
    '0': 0,
    '1-2': 0,
    '3-5': 0,
    '6-10': 0,
    '>10': 0,
}
domainCount = {}
path = 'cvelist/cvelist_4571'

def domain_count():
    global totalcount
    cve_list = []
    for file in os.listdir(path):
        totalcount += 1
        with open(f'{path}/{file}', 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
            except Exception as e:
                print(f"open file {file} error")
            tp: dict = data['containers']['cna']
            
            # 统计url
            if 'references' in tp.keys():
                references = tp['references']
                refNumber = len(references)
                if 7 < refNumber < 10:
                    cve_list.append(file.split('.')[0])
                # if refNumber == 0:
                #     urlCount['0'] += 1
                # elif refNumber <= 2:
                #     urlCount['1-2'] += 1
                # elif refNumber <= 5:
                #     urlCount['3-5'] += 1
                # elif refNumber <= 10:
                #     urlCount['6-10'] += 1
                # else:
                #     urlCount['>10'] += 1
                # for dic in references:
                #     url = dic['url']
                #     domain = get_domain(url)
                #     # print(domain)
                #     target = 'access.redhat.com'
                #     if domain == target:
                #         with open(f"urllist/url_list_{target}", 'a') as f:
                #             print(url, file=f)
                        # sys.exit(0)
                    # if domain in domainCount.keys():
                    #     domainCount[domain] += 1
                    # else:
                    #     domainCount[domain] = 1

    print(totalcount)
    print(len(cve_list))
    with open('cve_list.pkl', 'wb') as f:
        pickle.dump(cve_list, f)
    # sorted_items = sorted(domainCount.items(), key=lambda x: x[1], reverse=True)
    # with open('./new/domainCount', 'w') as f:
    #     for key, value in sorted_items:
    #         print(key, value, file=f)


def description_count():
    global totalcount
    for file in os.listdir(path):
        totalcount += 1
        with open(f'{path}/{file}', 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
            except Exception as e:
                print(f"open file {file} error")
            tp: dict = data['containers']['cna']

            # 统计description长度
            if 'descriptions' in tp.keys():
                descriptions = data['containers']['cna']['descriptions'][0]['value']
                wordsNumber = len(descriptions.split())
                # print(descriptions)
                # print(wordsNumber)
                # if wordsNumber > ans[0]:
                #     ans = (wordsNumber, fullPath)
                #     print(fullPath)
                if wordsNumber < 20:
                    with open("./new/0-20", 'a', encoding='utf-8') as f:
                        print(file[:-5], file=f)
                elif wordsNumber < 50:
                    with open("./new/20-50", 'a', encoding='utf-8') as f:
                        print(file[:-5], file=f)
                elif wordsNumber < 100:
                    with open("./new/50-100", 'a', encoding='utf-8') as f:
                        print(file[:-5], file=f)
                else:
                    with open("./new/over100", 'a', encoding='utf-8') as f:
                        print(file[:-5], file=f)
            elif 'rejectedReasons' in tp.keys():
                pass
            else:
                print("new,", file)

domain_count()
# description_count()