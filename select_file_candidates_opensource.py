import os
import sys

import tqdm
import torch
import pandas as pd
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from util import load_pickle, save_pickle, save_text

max_token = 8000
model_name = 'BAAI/bge-reranker-v2-m3'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
model.eval()

filter_list = [
    'changelog', 'news', 'changes', 'changelog', 'version', 'readme', 'makefile', 'license', 'authors', 'todo', 'TODO', 'history', 'copying', 'relnotes', 'thanks', 'notice','whatsnew', 'notes', 'release_notes', 'note', 'testlist', 'testsuite', 'test', '.gitignore', '.xlsx', '.xls', '.md', '.txt', '.doc', '.docx', '.pdf', '.rst', '.changes', '.rdoc', '.mdown', '.command', '.out', '.err', '.stderr', '.stdout', '.test', '.jpg', '.jpeg', '.png', '.svg', '.mp4', '.gif', '.exr', '.csv', '.rdf', '.ico', '.ttf', '.otf', '.woff', '.woff2', '.mock', '.stub', '.fake', '.ppt', '.pptx', '.key', '.bak', '.zip', '.gz', '.rar', '.bmp', '.yaml', '.yml', '.json', '.xml', '.ini', '.cfg', '.tar.gz', '.tgz', '.html', '.htm', '.css', '.cygport'
]


def rec(df, repo_name: str, full_path: str):
    file_name = full_path.split('/')[-1].lower()
    if os.path.isdir(full_path):
        for item in os.listdir(full_path):
            rec(df, repo_name, f'{full_path}/{item}')
    elif '.' not in file_name or 'test' in full_path or 'note' in full_path or 'license' in full_path or any(element in file_name for element in filter_list):
        pass
    else:
        try:
            with open(full_path, 'r') as f:
                content = f.read()
        except UnicodeDecodeError:      # 非文本文件
            return
        token_len = len(tokenizer.encode(content))
        if token_len > max_token:
            content_len = len(content)
            block_count = int(token_len / max_token) + 1
            block_size = int(content_len / block_count)
            cur = 0
            while cur + block_size < content_len:
                if content[cur : cur + block_size]:
                    df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[7:]), content[cur : cur + block_size]]
                cur += block_size                
            else:
                if cur < content_len:
                    df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[7:]), content[cur:]]
        elif content:
            df.loc[len(df)] = [repo_name, '/'.join(full_path.split('/')[7:]), content]


def split_file_content(cve: str):
    tp = model_name.split('/')[-1]
    output_file = f'/Volumes/NVD/experiment_data/267/content_{tp}/{cve}.csv'
    if os.path.exists(output_file):
        return pd.read_csv(output_file)
    
    with open(f'/Volumes/NVD/experiment_data/267/descriptions/{cve}') as f:
        description = f.read()
    df = pd.DataFrame(
        {
            'repo_name': ['null'],
            'file_name': ['null'],
            'content': [description]
        }
    )
    path = f'/Users/wangtao/Downloads/target/{cve}'
    repos = os.listdir(path)
    for repo in tqdm.tqdm(repos):
        repo_name = repo.replace('—', '/')
        rec(df, repo_name, f'{path}/{repo}')
    df.to_csv(output_file, index = False)
    return df
  

def calc_similarities(cve, df):
    tp = model_name.split('/')[-1]
    output_file = f'/Volumes/NVD/experiment_data/267/similarities_{tp}/{cve}.csv'
    if os.path.exists(output_file):
        return pd.read_csv(output_file)

    desc = df.loc[0].content
    similarities = []
    with torch.no_grad():
        for content in df.content:
            inputs = tokenizer([[content, desc]], padding=True, truncation=True, return_tensors='pt', max_length=8192)
            scores = model(**inputs, return_dict=True).logits.view(-1, ).float()
            similarities.append(scores)
    df['similarities'] = similarities
    df = df.sort_values('similarities', ascending = False)
    df.to_csv(output_file, index = False)
    return df


def select_file_candidates(k: int, ans: dict):
    # cve_list = load_pickle('/Volumes/NVD/experiment_data/267/procedure_data/cve_list_205.pkl')
    cve_list = [
        'CVE-2018-1000888', 'CVE-2015-8748', 'CVE-2019-11411', 'CVE-2019-11412'
    ]
    # cve_list = [
    #     'CVE-2018-1000888', 'CVE-2015-8748', 'CVE-2019-11411', 'CVE-2019-11412', 'CVE-2017-15010', 'CVE-2021-28363', 'CVE-2020-26137', 'CVE-2019-20479', 'CVE-2022-23614', 'CVE-2019-1010305', 'CVE-2020-8203', 'CVE-2022-24724', 'CVE-2013-7436', 'CVE-2020-9274', 'CVE-2019-15026', 'CVE-2022-29869', 'CVE-2020-4067', 'CVE-2019-16235', 'CVE-2019-16236', 'CVE-2019-16237', 'CVE-2020-14399', 'CVE-2020-14400', 'CVE-2020-14401', 'CVE-2019-19204', 'CVE-2019-1010319', 'CVE-2019-1010317', 'CVE-2020-27783', 'CVE-2018-1002200', 'CVE-2022-30784', 'CVE-2018-15127', 'CVE-2018-20019'
    # ]
    res = {}
    rank = {}
    for cve in tqdm.tqdm(cve_list):
        print('current cve:', cve)
        df = split_file_content(cve)
        df = calc_similarities(cve, df)

        df.drop(df.index[0], inplace = True)
        res[cve] = []
        rank[cve] = -1
        for index, (_, row) in enumerate(df.iterrows()):
            # if (row.repo_name, row.file_name) not in res[cve]:
            #     res[cve].append((row.repo_name, row.file_name))
            # if len(res[cve]) > k:
            #     break
            if row.file_name.lower() == ans[cve].lower():
                rank[cve] = index + 1
                break
    # save_pickle('/Volumes/NVD/experiment_data/267/result.pkl', rank)
    save_text('/Volumes/NVD/experizment_data/267/result', rank)
    return rank
    return res


if __name__ == '__main__':
    ans = {
        'CVE-2018-1000888': 'archive/tar.php',
        'CVE-2015-8748': 'radicale/rights/regex.py',
        'CVE-2019-11411': 'jsnumber.c',
        'CVE-2019-11412': 'jscompile.c',
        'CVE-2017-15010': 'lib/cookie.js', 
        'CVE-2021-28363': 'src/urllib3/connection.py',
        'CVE-2020-26137': 'src/urllib3/connection.py',
        'CVE-2019-20479': 'src/mod_auth_openidc.c',
        'CVE-2022-23614': 'src/extension/coreextension.php',
        'CVE-2019-1010305': 'libmspack/mspack/chmd.c',
        'CVE-2020-8203': 'lodash.js',
        'CVE-2022-24724': 'extensions/table.c',
        'CVE-2013-7436': 'include/webutil.js',
        'CVE-2020-9274': 'src/diraliases.c',
        'CVE-2019-15026': 'memcached.c',
        'CVE-2022-29869': 'mount.cifs.c',
        'CVE-2020-4067': 'src/apps/relay/ns_ioalib_engine_impl.c',
        'CVE-2019-16235': 'xmpp-vala/src/module/xep/0280_message_carbons.vala',
        'CVE-2019-16236': 'xmpp-vala/src/module/roster/module.vala',
        'CVE-2019-16237': 'xmpp-vala/src/module/xep/0313_message_archive_management.vala',
        'CVE-2020-14399': 'libvncclient/rfbproto.c',
        'CVE-2020-14400': 'libvncserver/translate.c',
        'CVE-2020-14401': 'libvncserver/scale.c',
        'CVE-2019-19204': 'src/regparse.c',
        'CVE-2019-1010319': 'cli/wave64.c',
        'CVE-2019-1010317': 'cli/caff.c',
        'CVE-2020-27783': 'src/lxml/html/clean.py',
        'CVE-2018-1002200': 'src/main/java/org/codehaus/plexus/archiver/abstractunarchiver.java',
        'CVE-2022-30784': 'libntfs-3g/attrib.c',
        'CVE-2018-15127': 'libvncserver/rfbserver.c',
        'CVE-2018-20019':'libvncclient/rfbproto.c'
    }
    select_file_candidates(10, ans)