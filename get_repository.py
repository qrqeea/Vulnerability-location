import os
import re
import json
import tqdm
import requests
from util import query_openai, save_text, save_pickle, load_pickle, get_domain


def get_product(s):
    pattern = r'(?<=:)([^:]+):([^:]+):([^:]+):([^:]+):([^:]+):'
    match = re.search(pattern, s)
    if match:
        return match.group(4)
    else:
        return None


def get_cpe_products(cve_list: list, cpe_json_path: str):
    # 遍历cpe_json文件，遇到目标cve，先查看reference url中是否有github链接，若有则提取repo；否则提取cpe_product
    # 返回两个dict
    # res_repo: {cve: {full_repo_name}}
    # res_cpe_product: {cve: {cpe_product}}
    
    res_repo = {}
    res_cpe_product = {}
    files = os.listdir(cpe_json_path)
    for file in tqdm.tqdm(files):
        if file in ['.DS_Store']:
            continue
        
        # print(f"current file: {file}")
        fileName = f'{cpe_json_path}/{file}'
        with open(fileName, 'r', encoding='utf-8', errors='ignore') as f:
            data = json.load(f)['CVE_Items']
        for cve_dic in data:
            cve_id = cve_dic['cve']['CVE_data_meta']['ID']
            if cve_id not in cve_list: continue
            
            repos = set()
            for item in cve_dic['cve']['references']['reference_data']:
                url = item['url']
                if get_domain(url) == 'github.com':
                    repos.add('/'.join(url.split('/')[3:5]))
            if repos:
                res_repo[cve_id] = repos
                continue

            res_cpe_product[cve_id] = set()
            cpe_list = cve_dic['configurations']['nodes'][0]['cpe_match']
            if not cpe_list:
                # CVE-2021-31810
                # CVE-2014-9390
                # CVE-2022-29526
                cpe_list = cpe_list = cve_dic['configurations']['nodes'][0]['children'][0]['cpe_match']
            for cpe_dic in cpe_list:
                cpe = cpe_dic['cpe23Uri']
                res_cpe_product[cve_id].add(get_product(cpe))
    return (res_repo, res_cpe_product)


def search_github_repositories(keyword, count = 3):
    base_url = "https://api.github.com/"
    search_endpoint = "search/repositories"
    params = {
        "q": keyword,
        "per_page": count
    }
    
    response = requests.get(base_url + search_endpoint, params=params)
    if response.status_code == 200:
        data = response.json()
        repositories = data["items"]
        # for repo in repositories:
        #     print(repo["html_url"])
        return [repo["html_url"] for repo in repositories]
    else:
        print("Error occurred: Status code", response.status_code)
        return None


def extract_repo_name(repo_url):
    if repo_url.startswith("https://github.com/"):
        path_components: list = repo_url[len("https://github.com/"):].split('/')
        path_components = [item for item in path_components if item != '']  # 去除空元素
        # 如果路径包含用户名和仓库名，则认为是仓库地址
        if len(path_components) >= 2:
            return f"{path_components[0]}/{path_components[1]}"
    return None


def get_product_url(cpe_product_dic: dict):
    products = set()
    for _, value in cpe_product_dic.items():
        products |= value
    # print(len(products))
        
    prompt_general = 'Give me the GitHub URL of #, answer within 100 tokens. Only output the URL, do not output prompt information.'
    product_repo_url = {}    # {product: [(repo_full_name, repo_url)]}
    
    tmp_file = 'repository_tmp.pkl'
    if os.path.exists(tmp_file):
        product_repo_url = load_pickle(tmp_file)
        print(len(product_repo_url))

    for product in tqdm.tqdm(products):
        if product_repo_url.get(product):
            continue

        prompt = prompt_general.replace('#', product)
        # print(prompt)
        try:
            # print('querying openai')
            url = query_openai(prompt, 'gpt-4-turbo')
            repo_full_name = extract_repo_name(url)
            if repo_full_name and requests.get(url).ok:
                product_repo_url[product] = [(repo_full_name, url)]
            else:
                urls = search_github_repositories(product)
                if urls:
                    tp = []
                    for url in urls:
                        repo_full_name = extract_repo_name(url)
                        if repo_full_name and requests.get(url).ok:
                            tp.append((repo_full_name, url))
                    product_repo_url[product] = tp
        except Exception:
            try:
                # print('second querying openai')
                url = query_openai(prompt)
                repo_full_name = extract_repo_name(url)
                if repo_full_name and requests.get(url).ok:
                    product_repo_url[product] = [(repo_full_name, url)]
                else:
                    urls = search_github_repositories(product)
                    if urls:
                        tp = []
                        for url in urls:
                            repo_full_name = extract_repo_name(url)
                            if repo_full_name and requests.get(url).ok:
                                tp.append((repo_full_name, url))
                        product_repo_url[product] = tp
            except Exception as e:
                # print(e)
                save_pickle(tmp_file, product_repo_url)

    return product_repo_url


def get_repository_by_product(cpe_product_dic: dict):
    # input: {cve: {cpe_products}}
    # 汇总所有product，依次询问gpt，然后验证是否有效，若无效通过github搜索，保留5个，{product: [(repo_full_name, repo_url)]}
    # 汇总输出：遍历input，对每个product，到2中查找，若存在，则输出{(cve, repo_full_name): url}
    
    product_repo_url = get_product_url(cpe_product_dic)
    # print(product_repo_url)
    res = {}
    for cve, products in cpe_product_dic.items():
        for product in products:
            if product_repo_url.get(product):
                for repo_full_name, url in product_repo_url[product]:
                    res[(cve, repo_full_name)] = url
    return res


def get_repository(cve_list: list, target_path: str):
    if os.path.exists(target_path):
        return load_pickle(f'{target_path}.pkl')

    cve_repo, cve_product = get_cpe_products(
        cve_list,
        '/Volumes/NVD/experiment_data/all/cpe_json'
    )
    
    # cve_product = {
    #     'CVE-2021-21996' :  {'salt'},
    #     'CVE-2021-22119' :  {'spring_security'},
    #     'CVE-2021-22696' :  {'cxf'},
    #     'CVE-2021-23450' :  {'dojo'},
    #     'CVE-2016-9459' :  {'owncloud', 'nextcloud_server'},
    #     'CVE-2016-9460' :  {'owncloud', 'nextcloud'}
    # }

    res = get_repository_by_product(cve_product)
    for cve, full_repo_name_set in cve_repo.items():
        for full_repo_name in full_repo_name_set:
            res[(cve, full_repo_name)] = 'https://github.com/' + full_repo_name
    
    save_text(target_path, res)
    save_pickle(f'{target_path}.pkl', res)

    return res


if __name__ == '__main__':
    cve_list = load_pickle('/Volumes/NVD/experiment_data/267/procedure_data/cve_list_267.pkl')
    get_repository(
        cve_list,
        '/Volumes/NVD/experiment_data/267/procedure_data/{(cve, repo_full_name): url}'
    )